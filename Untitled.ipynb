{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3221fbd4-f3e0-41c1-8ba7-73bad1bd152a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cvzone'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcvzone\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mHandTrackingModule\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HandDetector\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmath\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mctypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cast, POINTER\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'cvzone'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from cvzone.HandTrackingModule import HandDetector\n",
    "import math\n",
    "from ctypes import cast, POINTER\n",
    "from comtypes import CLSCTX_ALL\n",
    "from pycaw.pycaw import AudioUtilities, IAudioEndpointVolume\n",
    "import pyautogui  # ‡πÉ‡∏ä‡πâ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ñ‡∏ß‡∏ö‡∏Ñ‡∏∏‡∏°‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠\n",
    "import time\n",
    "\n",
    "# ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏Å‡∏•‡πâ‡∏≠‡∏á\n",
    "cap = cv2.VideoCapture(0)\n",
    "detector = HandDetector(detectionCon=0.8)  # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö\n",
    "\n",
    "# ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏£‡∏∞‡∏ö‡∏ö‡πÄ‡∏™‡∏µ‡∏¢‡∏á\n",
    "devices = AudioUtilities.GetSpeakers()\n",
    "interface = devices.Activate(IAudioEndpointVolume._iid_, CLSCTX_ALL, None)\n",
    "volume = cast(interface, POINTER(IAudioEndpointVolume))\n",
    "\n",
    "# ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏Ñ‡πà‡∏≤‡∏ï‡πà‡∏≥‡∏™‡∏∏‡∏î-‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î‡∏Ç‡∏≠‡∏á‡∏£‡∏∞‡∏¢‡∏∞‡∏°‡∏∑‡∏≠\n",
    "min_distance = 20\n",
    "max_distance = 180\n",
    "adjusting_volume = False  # ‡πÄ‡∏ä‡πá‡∏Ñ‡∏ß‡πà‡∏≤‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏õ‡∏£‡∏±‡∏ö‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏≠‡∏¢‡∏π‡πà‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà\n",
    "last_volume = volume.GetMasterVolumeLevelScalar()  # ‡πÄ‡∏Å‡πá‡∏ö‡∏£‡∏∞‡∏î‡∏±‡∏ö‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î\n",
    "\n",
    "# ‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£‡πÉ‡∏´‡∏°‡πà‡πÄ‡∏ä‡πá‡∏Ñ‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏Å‡∏≤‡∏£‡∏Å‡∏î\n",
    "last_action = None\n",
    "last_time = time.time()  # ‡πÉ‡∏ä‡πâ‡∏à‡∏±‡∏ö‡πÄ‡∏ß‡∏•‡∏≤‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô‡∏Å‡∏≤‡∏£‡∏Å‡∏î‡∏ã‡πâ‡∏≥\n",
    "last_move_time = time.time()  # ‡∏à‡∏±‡∏ö‡πÄ‡∏ß‡∏•‡∏≤‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡∏Ñ‡∏•‡∏¥‡∏õ\n",
    "last_skip_time = time.time()  # ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏à‡∏±‡∏ö‡πÄ‡∏ß‡∏•‡∏≤‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏Ç‡πâ‡∏≤‡∏°‡πÇ‡∏Ü‡∏©‡∏ì‡∏≤\n",
    "last_next_time = time.time()  # ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏à‡∏±‡∏ö‡πÄ‡∏ß‡∏•‡∏≤‡πÑ‡∏õ‡∏Ñ‡∏•‡∏¥‡∏õ‡∏ñ‡∏±‡∏î‡πÑ‡∏õ\n",
    "\n",
    "# ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡∏Ñ‡∏•‡∏¥‡∏õ\n",
    "move_interval = 1  # 1 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡∏Ñ‡∏•‡∏¥‡∏õ\n",
    "move_duration = 5  # 5 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡∏Ñ‡∏•‡∏¥‡∏õ\n",
    "skip_interval = 5  # 5 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ‡∏´‡∏•‡∏±‡∏á‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≤‡∏°‡πÇ‡∏Ü‡∏©‡∏ì‡∏≤\n",
    "next_interval = 5  # 5 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ‡∏´‡∏•‡∏±‡∏á‡∏à‡∏≤‡∏Å‡πÑ‡∏õ‡∏Ñ‡∏•‡∏¥‡∏õ‡∏ñ‡∏±‡∏î‡πÑ‡∏õ\n",
    "\n",
    "while True:\n",
    "    success, img = cap.read()\n",
    "    hands, img = detector.findHands(img)\n",
    "\n",
    "    if hands:\n",
    "        for hand in hands:\n",
    "            fingers = detector.fingersUp(hand)  # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ô‡∏¥‡πâ‡∏ß‡∏ó‡∏µ‡πà‡∏¢‡∏Å\n",
    "\n",
    "            if hand[\"type\"] == \"Right\" and len(hand[\"lmList\"]) >= 9:  # ‡∏°‡∏∑‡∏≠‡∏Ç‡∏ß‡∏≤ -> ‡∏Ñ‡∏ß‡∏ö‡∏Ñ‡∏∏‡∏°‡πÄ‡∏™‡∏µ‡∏¢‡∏á\n",
    "                if fingers == [1, 1, 1, 1, 1]:  # ‡∏Å‡∏≤‡∏á‡∏°‡∏∑‡∏≠ 5 ‡∏ô‡∏¥‡πâ‡∏ß -> ‡∏´‡∏¢‡∏∏‡∏î‡∏ó‡∏µ‡πà‡∏£‡∏∞‡∏î‡∏±‡∏ö‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÄ‡∏î‡∏¥‡∏°\n",
    "                    adjusting_volume = False  \n",
    "\n",
    "                elif fingers == [1, 1, 0, 0, 0]:  # ‡∏ä‡∏π‡πÅ‡∏Ñ‡πà‡πÇ‡∏õ‡πâ‡∏á‡∏Å‡∏±‡∏ö‡∏ä‡∏µ‡πâ -> ‡∏õ‡∏£‡∏±‡∏ö‡πÄ‡∏™‡∏µ‡∏¢‡∏á\n",
    "                    adjusting_volume = True\n",
    "                    thumb_tip = hand[\"lmList\"][4]\n",
    "                    index_tip = hand[\"lmList\"][8]\n",
    "                    \n",
    "                    # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏£‡∏∞‡∏¢‡∏∞‡∏´‡πà‡∏≤‡∏á‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏ô‡∏¥‡πâ‡∏ß‡πÇ‡∏õ‡πâ‡∏á‡πÅ‡∏•‡∏∞‡∏ô‡∏¥‡πâ‡∏ß‡∏ä‡∏µ‡πâ\n",
    "                    distance_x = abs(thumb_tip[0] - index_tip[0])\n",
    "                    distance_y = abs(thumb_tip[1] - index_tip[1])\n",
    "                    distance = math.hypot(distance_x, distance_y)\n",
    "                    distance = max(min_distance, min(distance, max_distance))\n",
    "\n",
    "                    volume_scalar = (distance - min_distance) / (max_distance - min_distance)\n",
    "\n",
    "                    # ‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏ô‡∏∏‡πà‡∏°‡∏ô‡∏ß‡∏•‡∏Ç‡∏∂‡πâ‡∏ô\n",
    "                    smooth_factor = 0.2  \n",
    "                    last_volume = (1 - smooth_factor) * last_volume + smooth_factor * volume_scalar\n",
    "\n",
    "                    # ‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏ñ‡πâ‡∏≤‡∏ï‡πà‡∏≤‡∏á‡∏Å‡∏±‡∏ô‡∏ô‡πâ‡∏≠‡∏¢‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ\n",
    "                    if abs(volume.GetMasterVolumeLevelScalar() - last_volume) > 0.02:\n",
    "                        volume.SetMasterVolumeLevelScalar(last_volume, None)\n",
    "\n",
    "                    # ‡∏ß‡∏≤‡∏î‡πÄ‡∏™‡πâ‡∏ô‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏ô‡∏¥‡πâ‡∏ß‡πÇ‡∏õ‡πâ‡∏á‡∏Å‡∏±‡∏ö‡∏ä‡∏µ‡πâ\n",
    "                    cv2.line(img, (thumb_tip[0], thumb_tip[1]), (index_tip[0], index_tip[1]), (0, 255, 0), 3)\n",
    "\n",
    "                # ‡πÅ‡∏™‡∏î‡∏á‡∏£‡∏∞‡∏î‡∏±‡∏ö‡πÄ‡∏™‡∏µ‡∏¢‡∏á\n",
    "                volume_percent = int(last_volume * 100)\n",
    "                cv2.putText(img, f'Volume: {volume_percent}%', (50, 50),\n",
    "                            cv2.FONT_HERSHEY_COMPLEX, 1, (255, 0, 0), 2)\n",
    "\n",
    "                # ‡πÅ‡∏™‡∏î‡∏á‡πÅ‡∏ñ‡∏ö‡∏£‡∏∞‡∏î‡∏±‡∏ö‡πÄ‡∏™‡∏µ‡∏¢‡∏á\n",
    "                bar_height = int((1 - last_volume) * 300)\n",
    "                bar_color = (0, 255, 0) if last_volume > 0.5 else (0, 0, 255)  # ‡∏™‡∏µ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ß = ‡∏î‡∏±‡∏á, ‡πÅ‡∏î‡∏á = ‡πÄ‡∏ö‡∏≤\n",
    "                cv2.rectangle(img, (50, 100), (100, 400), (255, 0, 0), 3)  \n",
    "                cv2.rectangle(img, (50, 100 + bar_height), (100, 400), bar_color, -1)\n",
    "\n",
    "                # ‡πÅ‡∏™‡∏î‡∏á‡πÑ‡∏≠‡∏Ñ‡∏≠‡∏ô‡πÄ‡∏™‡∏µ‡∏¢‡∏á\n",
    "                cv2.putText(img, \"üîä\" if last_volume > 0.5 else \"üîà\", (120, 380), \n",
    "                            cv2.FONT_HERSHEY_COMPLEX, 1, bar_color, 2)\n",
    "\n",
    "            elif hand[\"type\"] == \"Left\" and len(hand[\"lmList\"]) >= 9:  # ‡∏°‡∏∑‡∏≠‡∏ã‡πâ‡∏≤‡∏¢ -> ‡∏Ñ‡∏ß‡∏ö‡∏Ñ‡∏∏‡∏°‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠\n",
    "                current_time = time.time()\n",
    "\n",
    "                if current_time - last_time > 1:  # ‡πÄ‡∏ä‡πá‡∏Ñ‡πÄ‡∏ß‡∏•‡∏≤‡∏´‡πà‡∏≤‡∏á‡∏Å‡∏±‡∏ô 1 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ\n",
    "                    if fingers == [0, 1, 0, 0, 0]:  # ‡∏ä‡∏µ‡πâ‡∏ô‡∏¥‡πâ‡∏ß‡∏°‡∏∑‡∏≠‡∏ã‡πâ‡∏≤‡∏¢‡πÑ‡∏õ‡∏ó‡∏≤‡∏á‡∏Ç‡∏ß‡∏≤ (‡πÄ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡∏Ñ‡∏•‡∏¥‡∏õ‡πÑ‡∏õ‡∏Ç‡πâ‡∏≤‡∏á‡∏´‡∏ô‡πâ‡∏≤ 5 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ)\n",
    "                        if current_time - last_move_time > move_interval:\n",
    "                            pyautogui.press('right')  # ‡πÄ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡∏Ñ‡∏•‡∏¥‡∏õ‡πÑ‡∏õ‡∏Ç‡πâ‡∏≤‡∏á‡∏´‡∏ô‡πâ‡∏≤ 5 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ\n",
    "                            last_move_time = current_time  # ‡∏£‡∏µ‡πÄ‡∏ã‡πá‡∏ï‡πÄ‡∏ß‡∏•‡∏≤‡∏Å‡∏≤‡∏£‡πÄ‡∏•‡∏∑‡πà‡∏≠‡∏ô\n",
    "\n",
    "                    elif fingers == [0, 1, 1, 0, 0]:  # ‡∏ä‡∏µ‡πâ 2 ‡∏ô‡∏¥‡πâ‡∏ß (‡∏ô‡∏¥‡πâ‡∏ß‡∏ä‡∏µ‡πâ, ‡∏ô‡∏¥‡πâ‡∏ß‡∏Å‡∏•‡∏≤‡∏á) (‡∏¢‡πâ‡∏≠‡∏ô‡∏Ñ‡∏•‡∏¥‡∏õ 5 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ)\n",
    "                        if current_time - last_move_time > move_interval:\n",
    "                            pyautogui.press('left')  # ‡πÄ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡∏Ñ‡∏•‡∏¥‡∏õ‡∏¢‡πâ‡∏≠‡∏ô‡∏Å‡∏•‡∏±‡∏ö 5 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ\n",
    "                            last_move_time = current_time  # ‡∏£‡∏µ‡πÄ‡∏ã‡πá‡∏ï‡πÄ‡∏ß‡∏•‡∏≤‡∏Å‡∏≤‡∏£‡πÄ‡∏•‡∏∑‡πà‡∏≠‡∏ô\n",
    "\n",
    "\n",
    "                    # ‡πÑ‡∏õ‡∏Ñ‡∏•‡∏¥‡∏õ‡∏ñ‡∏±‡∏î‡πÑ‡∏õ\n",
    "                    elif fingers == [0, 1, 1, 1, 1]:  # ‡∏ä‡∏µ‡πâ 4 ‡∏ô‡∏¥‡πâ‡∏ß (‡∏ä‡∏µ‡πâ‡∏ô‡∏¥‡πâ‡∏ß, ‡∏ô‡∏¥‡πâ‡∏ß‡∏Å‡∏•‡∏≤‡∏á, ‡∏ô‡∏¥‡πâ‡∏ß‡∏ô‡∏≤‡∏á, ‡∏ô‡∏¥‡πâ‡∏ß‡∏Å‡πâ‡∏≠‡∏¢)\n",
    "                        if current_time - last_next_time > next_interval:  # 5 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ\n",
    "                            pyautogui.hotkey('shift', 'n')  # ‡πÉ‡∏ä‡πâ shift + n ‡πÑ‡∏õ‡∏Ñ‡∏•‡∏¥‡∏õ‡∏ñ‡∏±‡∏î‡πÑ‡∏õ\n",
    "                            last_next_time = current_time  # ‡∏£‡∏µ‡πÄ‡∏ã‡πá‡∏ï‡πÄ‡∏ß‡∏•‡∏≤‡∏Å‡∏≤‡∏£‡πÑ‡∏õ‡∏Ñ‡∏•‡∏¥‡∏õ‡∏ñ‡∏±‡∏î‡πÑ‡∏õ\n",
    "\n",
    "\n",
    "                    elif fingers == [0, 0, 0, 0, 1]:  # ‡∏Å‡∏≥‡∏°‡∏∑‡∏≠ = ‡∏´‡∏¢‡∏∏‡∏î‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠\n",
    "                        pyautogui.press('space')  \n",
    "                        last_time = current_time  # ‡∏£‡∏µ‡πÄ‡∏ã‡πá‡∏ï‡πÄ‡∏ß‡∏•‡∏≤\n",
    "\n",
    "                    elif fingers == [1, 1, 1, 1, 1]:  # ‡πÅ‡∏ö‡∏°‡∏∑‡∏≠ 5 ‡∏ô‡∏¥‡πâ‡∏ß = ‡πÄ‡∏•‡πà‡∏ô‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠‡∏ï‡πà‡∏≠\n",
    "                        pyautogui.press('space')  \n",
    "                        last_time = current_time  # ‡∏£‡∏µ‡πÄ‡∏ã‡πá‡∏ï‡πÄ‡∏ß‡∏•‡∏≤\n",
    "\n",
    "    img = cv2.resize(img, (960, 720))\n",
    "    cv2.imshow(\"image\", img)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd5de7c9-a7b3-47bc-b18b-dfbb229686dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "  Using cached opencv_python-4.11.0.86-cp37-abi3-win_amd64.whl.metadata (20 kB)\n",
      "Collecting opencv-contrib-python\n",
      "  Using cached opencv_contrib_python-4.11.0.86-cp37-abi3-win_amd64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\ravip\\anaconda3\\lib\\site-packages (from opencv-python) (1.26.4)\n",
      "Using cached opencv_python-4.11.0.86-cp37-abi3-win_amd64.whl (39.5 MB)\n",
      "Using cached opencv_contrib_python-4.11.0.86-cp37-abi3-win_amd64.whl (46.2 MB)\n",
      "Installing collected packages: opencv-python, opencv-contrib-python\n",
      "Successfully installed opencv-contrib-python-4.11.0.86 opencv-python-4.11.0.86\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade opencv-python opencv-contrib-python\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "83aef184-cd40-4640-9260-784719b3a147",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ravip\\anaconda3\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6d7b2bd-0176-4c4f-bded-4b2b6d29415a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\users\\ravip\\anaconda3\\lib\\site-packages (4.11.0.86)\n",
      "Requirement already satisfied: opencv-contrib-python in c:\\users\\ravip\\anaconda3\\lib\\site-packages (4.11.0.86)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\ravip\\anaconda3\\lib\\site-packages (from opencv-python) (1.26.4)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install --upgrade opencv-python opencv-contrib-python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f221a62c-fc7f-4213-9212-739dab0f074e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.11.0\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "print(cv2.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "926de551-4624-4b8e-b9c5-6949b700f2d1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cvzone'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcvzone\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mHandTrackingModule\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HandDetector\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmath\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mctypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cast, POINTER\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'cvzone'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from cvzone.HandTrackingModule import HandDetector\n",
    "import math\n",
    "from ctypes import cast, POINTER\n",
    "from comtypes import CLSCTX_ALL\n",
    "from pycaw.pycaw import AudioUtilities, IAudioEndpointVolume\n",
    "import pyautogui  # ‡πÉ‡∏ä‡πâ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ñ‡∏ß‡∏ö‡∏Ñ‡∏∏‡∏°‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠\n",
    "import time\n",
    "\n",
    "# ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏Å‡∏•‡πâ‡∏≠‡∏á\n",
    "cap = cv2.VideoCapture(0)\n",
    "detector = HandDetector(detectionCon=0.8)  # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö\n",
    "\n",
    "# ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏£‡∏∞‡∏ö‡∏ö‡πÄ‡∏™‡∏µ‡∏¢‡∏á\n",
    "devices = AudioUtilities.GetSpeakers()\n",
    "interface = devices.Activate(IAudioEndpointVolume._iid_, CLSCTX_ALL, None)\n",
    "volume = cast(interface, POINTER(IAudioEndpointVolume))\n",
    "\n",
    "# ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏Ñ‡πà‡∏≤‡∏ï‡πà‡∏≥‡∏™‡∏∏‡∏î-‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î‡∏Ç‡∏≠‡∏á‡∏£‡∏∞‡∏¢‡∏∞‡∏°‡∏∑‡∏≠\n",
    "min_distance = 20\n",
    "max_distance = 180\n",
    "adjusting_volume = False  # ‡πÄ‡∏ä‡πá‡∏Ñ‡∏ß‡πà‡∏≤‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏õ‡∏£‡∏±‡∏ö‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏≠‡∏¢‡∏π‡πà‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà\n",
    "last_volume = volume.GetMasterVolumeLevelScalar()  # ‡πÄ‡∏Å‡πá‡∏ö‡∏£‡∏∞‡∏î‡∏±‡∏ö‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î\n",
    "\n",
    "# ‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£‡πÉ‡∏´‡∏°‡πà‡πÄ‡∏ä‡πá‡∏Ñ‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏Å‡∏≤‡∏£‡∏Å‡∏î\n",
    "last_action = None\n",
    "last_time = time.time()  # ‡πÉ‡∏ä‡πâ‡∏à‡∏±‡∏ö‡πÄ‡∏ß‡∏•‡∏≤‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô‡∏Å‡∏≤‡∏£‡∏Å‡∏î‡∏ã‡πâ‡∏≥\n",
    "last_move_time = time.time()  # ‡∏à‡∏±‡∏ö‡πÄ‡∏ß‡∏•‡∏≤‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡∏Ñ‡∏•‡∏¥‡∏õ\n",
    "last_skip_time = time.time()  # ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏à‡∏±‡∏ö‡πÄ‡∏ß‡∏•‡∏≤‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏Ç‡πâ‡∏≤‡∏°‡πÇ‡∏Ü‡∏©‡∏ì‡∏≤\n",
    "last_next_time = time.time()  # ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏à‡∏±‡∏ö‡πÄ‡∏ß‡∏•‡∏≤‡πÑ‡∏õ‡∏Ñ‡∏•‡∏¥‡∏õ‡∏ñ‡∏±‡∏î‡πÑ‡∏õ\n",
    "\n",
    "# ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡∏Ñ‡∏•‡∏¥‡∏õ\n",
    "move_interval = 1  # 1 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡∏Ñ‡∏•‡∏¥‡∏õ\n",
    "move_duration = 5  # 5 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡∏Ñ‡∏•‡∏¥‡∏õ\n",
    "skip_interval = 5  # 5 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ‡∏´‡∏•‡∏±‡∏á‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≤‡∏°‡πÇ‡∏Ü‡∏©‡∏ì‡∏≤\n",
    "next_interval = 5  # 5 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ‡∏´‡∏•‡∏±‡∏á‡∏à‡∏≤‡∏Å‡πÑ‡∏õ‡∏Ñ‡∏•‡∏¥‡∏õ‡∏ñ‡∏±‡∏î‡πÑ‡∏õ\n",
    "\n",
    "while True:\n",
    "    success, img = cap.read()\n",
    "    hands, img = detector.findHands(img)\n",
    "\n",
    "    if hands:\n",
    "        for hand in hands:\n",
    "            fingers = detector.fingersUp(hand)  # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ô‡∏¥‡πâ‡∏ß‡∏ó‡∏µ‡πà‡∏¢‡∏Å\n",
    "\n",
    "            if hand[\"type\"] == \"Right\" and len(hand[\"lmList\"]) >= 9:  # ‡∏°‡∏∑‡∏≠‡∏Ç‡∏ß‡∏≤ -> ‡∏Ñ‡∏ß‡∏ö‡∏Ñ‡∏∏‡∏°‡πÄ‡∏™‡∏µ‡∏¢‡∏á\n",
    "                if fingers == [1, 1, 1, 1, 1]:  # ‡∏Å‡∏≤‡∏á‡∏°‡∏∑‡∏≠ 5 ‡∏ô‡∏¥‡πâ‡∏ß -> ‡∏´‡∏¢‡∏∏‡∏î‡∏ó‡∏µ‡πà‡∏£‡∏∞‡∏î‡∏±‡∏ö‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÄ‡∏î‡∏¥‡∏°\n",
    "                    adjusting_volume = False  \n",
    "\n",
    "                elif fingers == [1, 1, 0, 0, 0]:  # ‡∏ä‡∏π‡πÅ‡∏Ñ‡πà‡πÇ‡∏õ‡πâ‡∏á‡∏Å‡∏±‡∏ö‡∏ä‡∏µ‡πâ -> ‡∏õ‡∏£‡∏±‡∏ö‡πÄ‡∏™‡∏µ‡∏¢‡∏á\n",
    "                    adjusting_volume = True\n",
    "                    thumb_tip = hand[\"lmList\"][4]\n",
    "                    index_tip = hand[\"lmList\"][8]\n",
    "                    \n",
    "                    # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏£‡∏∞‡∏¢‡∏∞‡∏´‡πà‡∏≤‡∏á‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏ô‡∏¥‡πâ‡∏ß‡πÇ‡∏õ‡πâ‡∏á‡πÅ‡∏•‡∏∞‡∏ô‡∏¥‡πâ‡∏ß‡∏ä‡∏µ‡πâ\n",
    "                    distance_x = abs(thumb_tip[0] - index_tip[0])\n",
    "                    distance_y = abs(thumb_tip[1] - index_tip[1])\n",
    "                    distance = math.hypot(distance_x, distance_y)\n",
    "                    distance = max(min_distance, min(distance, max_distance))\n",
    "\n",
    "                    volume_scalar = (distance - min_distance) / (max_distance - min_distance)\n",
    "\n",
    "                    # ‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏ô‡∏∏‡πà‡∏°‡∏ô‡∏ß‡∏•‡∏Ç‡∏∂‡πâ‡∏ô\n",
    "                    smooth_factor = 0.2  \n",
    "                    last_volume = (1 - smooth_factor) * last_volume + smooth_factor * volume_scalar\n",
    "\n",
    "                    # ‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏ñ‡πâ‡∏≤‡∏ï‡πà‡∏≤‡∏á‡∏Å‡∏±‡∏ô‡∏ô‡πâ‡∏≠‡∏¢‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ\n",
    "                    if abs(volume.GetMasterVolumeLevelScalar() - last_volume) > 0.02:\n",
    "                        volume.SetMasterVolumeLevelScalar(last_volume, None)\n",
    "\n",
    "                    # ‡∏ß‡∏≤‡∏î‡πÄ‡∏™‡πâ‡∏ô‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏ô‡∏¥‡πâ‡∏ß‡πÇ‡∏õ‡πâ‡∏á‡∏Å‡∏±‡∏ö‡∏ä‡∏µ‡πâ\n",
    "                    cv2.line(img, (thumb_tip[0], thumb_tip[1]), (index_tip[0], index_tip[1]), (0, 255, 0), 3)\n",
    "\n",
    "                # ‡πÅ‡∏™‡∏î‡∏á‡∏£‡∏∞‡∏î‡∏±‡∏ö‡πÄ‡∏™‡∏µ‡∏¢‡∏á\n",
    "                volume_percent = int(last_volume * 100)\n",
    "                cv2.putText(img, f'Volume: {volume_percent}%', (50, 50),\n",
    "                            cv2.FONT_HERSHEY_COMPLEX, 1, (255, 0, 0), 2)\n",
    "\n",
    "                # ‡πÅ‡∏™‡∏î‡∏á‡πÅ‡∏ñ‡∏ö‡∏£‡∏∞‡∏î‡∏±‡∏ö‡πÄ‡∏™‡∏µ‡∏¢‡∏á\n",
    "                bar_height = int((1 - last_volume) * 300)\n",
    "                bar_color = (0, 255, 0) if last_volume > 0.5 else (0, 0, 255)  # ‡∏™‡∏µ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ß = ‡∏î‡∏±‡∏á, ‡πÅ‡∏î‡∏á = ‡πÄ‡∏ö‡∏≤\n",
    "                cv2.rectangle(img, (50, 100), (100, 400), (255, 0, 0), 3)  \n",
    "                cv2.rectangle(img, (50, 100 + bar_height), (100, 400), bar_color, -1)\n",
    "\n",
    "                # ‡πÅ‡∏™‡∏î‡∏á‡πÑ‡∏≠‡∏Ñ‡∏≠‡∏ô‡πÄ‡∏™‡∏µ‡∏¢‡∏á\n",
    "                cv2.putText(img, \"üîä\" if last_volume > 0.5 else \"üîà\", (120, 380), \n",
    "                            cv2.FONT_HERSHEY_COMPLEX, 1, bar_color, 2)\n",
    "\n",
    "            elif hand[\"type\"] == \"Left\" and len(hand[\"lmList\"]) >= 9:  # ‡∏°‡∏∑‡∏≠‡∏ã‡πâ‡∏≤‡∏¢ -> ‡∏Ñ‡∏ß‡∏ö‡∏Ñ‡∏∏‡∏°‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠\n",
    "                current_time = time.time()\n",
    "\n",
    "                if current_time - last_time > 1:  # ‡πÄ‡∏ä‡πá‡∏Ñ‡πÄ‡∏ß‡∏•‡∏≤‡∏´‡πà‡∏≤‡∏á‡∏Å‡∏±‡∏ô 1 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ\n",
    "                    if fingers == [0, 1, 0, 0, 0]:  # ‡∏ä‡∏µ‡πâ‡∏ô‡∏¥‡πâ‡∏ß‡∏°‡∏∑‡∏≠‡∏ã‡πâ‡∏≤‡∏¢‡πÑ‡∏õ‡∏ó‡∏≤‡∏á‡∏Ç‡∏ß‡∏≤ (‡πÄ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡∏Ñ‡∏•‡∏¥‡∏õ‡πÑ‡∏õ‡∏Ç‡πâ‡∏≤‡∏á‡∏´‡∏ô‡πâ‡∏≤ 5 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ)\n",
    "                        if current_time - last_move_time > move_interval:\n",
    "                            pyautogui.press('right')  # ‡πÄ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡∏Ñ‡∏•‡∏¥‡∏õ‡πÑ‡∏õ‡∏Ç‡πâ‡∏≤‡∏á‡∏´‡∏ô‡πâ‡∏≤ 5 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ\n",
    "                            last_move_time = current_time  # ‡∏£‡∏µ‡πÄ‡∏ã‡πá‡∏ï‡πÄ‡∏ß‡∏•‡∏≤‡∏Å‡∏≤‡∏£‡πÄ‡∏•‡∏∑‡πà‡∏≠‡∏ô\n",
    "\n",
    "                    elif fingers == [0, 1, 1, 0, 0]:  # ‡∏ä‡∏µ‡πâ 2 ‡∏ô‡∏¥‡πâ‡∏ß (‡∏ô‡∏¥‡πâ‡∏ß‡∏ä‡∏µ‡πâ, ‡∏ô‡∏¥‡πâ‡∏ß‡∏Å‡∏•‡∏≤‡∏á) (‡∏¢‡πâ‡∏≠‡∏ô‡∏Ñ‡∏•‡∏¥‡∏õ 5 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ)\n",
    "                        if current_time - last_move_time > move_interval:\n",
    "                            pyautogui.press('left')  # ‡πÄ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡∏Ñ‡∏•‡∏¥‡∏õ‡∏¢‡πâ‡∏≠‡∏ô‡∏Å‡∏•‡∏±‡∏ö 5 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ\n",
    "                            last_move_time = current_time  # ‡∏£‡∏µ‡πÄ‡∏ã‡πá‡∏ï‡πÄ‡∏ß‡∏•‡∏≤‡∏Å‡∏≤‡∏£‡πÄ‡∏•‡∏∑‡πà‡∏≠‡∏ô\n",
    "\n",
    "\n",
    "                    # ‡πÑ‡∏õ‡∏Ñ‡∏•‡∏¥‡∏õ‡∏ñ‡∏±‡∏î‡πÑ‡∏õ\n",
    "                    elif fingers == [0, 1, 1, 1, 1]:  # ‡∏ä‡∏µ‡πâ 4 ‡∏ô‡∏¥‡πâ‡∏ß (‡∏ä‡∏µ‡πâ‡∏ô‡∏¥‡πâ‡∏ß, ‡∏ô‡∏¥‡πâ‡∏ß‡∏Å‡∏•‡∏≤‡∏á, ‡∏ô‡∏¥‡πâ‡∏ß‡∏ô‡∏≤‡∏á, ‡∏ô‡∏¥‡πâ‡∏ß‡∏Å‡πâ‡∏≠‡∏¢)\n",
    "                        if current_time - last_next_time > next_interval:  # 5 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ\n",
    "                            pyautogui.hotkey('shift', 'n')  # ‡πÉ‡∏ä‡πâ shift + n ‡πÑ‡∏õ‡∏Ñ‡∏•‡∏¥‡∏õ‡∏ñ‡∏±‡∏î‡πÑ‡∏õ\n",
    "                            last_next_time = current_time  # ‡∏£‡∏µ‡πÄ‡∏ã‡πá‡∏ï‡πÄ‡∏ß‡∏•‡∏≤‡∏Å‡∏≤‡∏£‡πÑ‡∏õ‡∏Ñ‡∏•‡∏¥‡∏õ‡∏ñ‡∏±‡∏î‡πÑ‡∏õ\n",
    "\n",
    "\n",
    "                    elif fingers == [0, 0, 0, 0, 1]:  # ‡∏Å‡∏≥‡∏°‡∏∑‡∏≠ = ‡∏´‡∏¢‡∏∏‡∏î‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠\n",
    "                        pyautogui.press('space')  \n",
    "                        last_time = current_time  # ‡∏£‡∏µ‡πÄ‡∏ã‡πá‡∏ï‡πÄ‡∏ß‡∏•‡∏≤\n",
    "\n",
    "                    elif fingers == [1, 1, 1, 1, 1]:  # ‡πÅ‡∏ö‡∏°‡∏∑‡∏≠ 5 ‡∏ô‡∏¥‡πâ‡∏ß = ‡πÄ‡∏•‡πà‡∏ô‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠‡∏ï‡πà‡∏≠\n",
    "                        pyautogui.press('space')  \n",
    "                        last_time = current_time  # ‡∏£‡∏µ‡πÄ‡∏ã‡πá‡∏ï‡πÄ‡∏ß‡∏•‡∏≤\n",
    "\n",
    "    img = cv2.resize(img, (960, 720))\n",
    "    cv2.imshow(\"image\", img)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7b96256e-78ae-40c2-993a-3e146aa8ac35",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cvzone'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcvzone\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mHandTrackingModule\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HandDetector\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmath\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mctypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cast, POINTER\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'cvzone'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from cvzone.HandTrackingModule import HandDetector\n",
    "import math\n",
    "from ctypes import cast, POINTER\n",
    "from comtypes import CLSCTX_ALL\n",
    "from pycaw.pycaw import AudioUtilities, IAudioEndpointVolume\n",
    "import pyautogui  # ‡πÉ‡∏ä‡πâ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ñ‡∏ß‡∏ö‡∏Ñ‡∏∏‡∏°‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠\n",
    "import time\n",
    "\n",
    "# ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏Å‡∏•‡πâ‡∏≠‡∏á\n",
    "cap = cv2.VideoCapture(0)\n",
    "detector = HandDetector(detectionCon=0.8)  # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö\n",
    "\n",
    "# ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏£‡∏∞‡∏ö‡∏ö‡πÄ‡∏™‡∏µ‡∏¢‡∏á\n",
    "devices = AudioUtilities.GetSpeakers()\n",
    "interface = devices.Activate(IAudioEndpointVolume._iid_, CLSCTX_ALL, None)\n",
    "volume = cast(interface, POINTER(IAudioEndpointVolume))\n",
    "\n",
    "# ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏Ñ‡πà‡∏≤‡∏ï‡πà‡∏≥‡∏™‡∏∏‡∏î-‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î‡∏Ç‡∏≠‡∏á‡∏£‡∏∞‡∏¢‡∏∞‡∏°‡∏∑‡∏≠\n",
    "min_distance = 20\n",
    "max_distance = 180\n",
    "adjusting_volume = False  # ‡πÄ‡∏ä‡πá‡∏Ñ‡∏ß‡πà‡∏≤‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏õ‡∏£‡∏±‡∏ö‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏≠‡∏¢‡∏π‡πà‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà\n",
    "last_volume = volume.GetMasterVolumeLevelScalar()  # ‡πÄ‡∏Å‡πá‡∏ö‡∏£‡∏∞‡∏î‡∏±‡∏ö‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î\n",
    "\n",
    "# ‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£‡πÉ‡∏´‡∏°‡πà‡πÄ‡∏ä‡πá‡∏Ñ‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏Å‡∏≤‡∏£‡∏Å‡∏î\n",
    "last_action = None\n",
    "last_time = time.time()  # ‡πÉ‡∏ä‡πâ‡∏à‡∏±‡∏ö‡πÄ‡∏ß‡∏•‡∏≤‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô‡∏Å‡∏≤‡∏£‡∏Å‡∏î‡∏ã‡πâ‡∏≥\n",
    "last_move_time = time.time()  # ‡∏à‡∏±‡∏ö‡πÄ‡∏ß‡∏•‡∏≤‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡∏Ñ‡∏•‡∏¥‡∏õ\n",
    "last_skip_time = time.time()  # ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏à‡∏±‡∏ö‡πÄ‡∏ß‡∏•‡∏≤‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏Ç‡πâ‡∏≤‡∏°‡πÇ‡∏Ü‡∏©‡∏ì‡∏≤\n",
    "last_next_time = time.time()  # ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏à‡∏±‡∏ö‡πÄ‡∏ß‡∏•‡∏≤‡πÑ‡∏õ‡∏Ñ‡∏•‡∏¥‡∏õ‡∏ñ‡∏±‡∏î‡πÑ‡∏õ\n",
    "\n",
    "# ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡∏Ñ‡∏•‡∏¥‡∏õ\n",
    "move_interval = 1  # 1 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡∏Ñ‡∏•‡∏¥‡∏õ\n",
    "move_duration = 5  # 5 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡∏Ñ‡∏•‡∏¥‡∏õ\n",
    "skip_interval = 5  # 5 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ‡∏´‡∏•‡∏±‡∏á‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≤‡∏°‡πÇ‡∏Ü‡∏©‡∏ì‡∏≤\n",
    "next_interval = 5  # 5 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ‡∏´‡∏•‡∏±‡∏á‡∏à‡∏≤‡∏Å‡πÑ‡∏õ‡∏Ñ‡∏•‡∏¥‡∏õ‡∏ñ‡∏±‡∏î‡πÑ‡∏õ\n",
    "\n",
    "while True:\n",
    "    success, img = cap.read()\n",
    "    hands, img = detector.findHands(img)\n",
    "\n",
    "    if hands:\n",
    "        for hand in hands:\n",
    "            fingers = detector.fingersUp(hand)  # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ô‡∏¥‡πâ‡∏ß‡∏ó‡∏µ‡πà‡∏¢‡∏Å\n",
    "\n",
    "            if hand[\"type\"] == \"Right\" and len(hand[\"lmList\"]) >= 9:  # ‡∏°‡∏∑‡∏≠‡∏Ç‡∏ß‡∏≤ -> ‡∏Ñ‡∏ß‡∏ö‡∏Ñ‡∏∏‡∏°‡πÄ‡∏™‡∏µ‡∏¢‡∏á\n",
    "                if fingers == [1, 1, 1, 1, 1]:  # ‡∏Å‡∏≤‡∏á‡∏°‡∏∑‡∏≠ 5 ‡∏ô‡∏¥‡πâ‡∏ß -> ‡∏´‡∏¢‡∏∏‡∏î‡∏ó‡∏µ‡πà‡∏£‡∏∞‡∏î‡∏±‡∏ö‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÄ‡∏î‡∏¥‡∏°\n",
    "                    adjusting_volume = False  \n",
    "\n",
    "                elif fingers == [1, 1, 0, 0, 0]:  # ‡∏ä‡∏π‡πÅ‡∏Ñ‡πà‡πÇ‡∏õ‡πâ‡∏á‡∏Å‡∏±‡∏ö‡∏ä‡∏µ‡πâ -> ‡∏õ‡∏£‡∏±‡∏ö‡πÄ‡∏™‡∏µ‡∏¢‡∏á\n",
    "                    adjusting_volume = True\n",
    "                    thumb_tip = hand[\"lmList\"][4]\n",
    "                    index_tip = hand[\"lmList\"][8]\n",
    "                    \n",
    "                    # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏£‡∏∞‡∏¢‡∏∞‡∏´‡πà‡∏≤‡∏á‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏ô‡∏¥‡πâ‡∏ß‡πÇ‡∏õ‡πâ‡∏á‡πÅ‡∏•‡∏∞‡∏ô‡∏¥‡πâ‡∏ß‡∏ä‡∏µ‡πâ\n",
    "                    distance_x = abs(thumb_tip[0] - index_tip[0])\n",
    "                    distance_y = abs(thumb_tip[1] - index_tip[1])\n",
    "                    distance = math.hypot(distance_x, distance_y)\n",
    "                    distance = max(min_distance, min(distance, max_distance))\n",
    "\n",
    "                    volume_scalar = (distance - min_distance) / (max_distance - min_distance)\n",
    "\n",
    "                    # ‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏ô‡∏∏‡πà‡∏°‡∏ô‡∏ß‡∏•‡∏Ç‡∏∂‡πâ‡∏ô\n",
    "                    smooth_factor = 0.2  \n",
    "                    last_volume = (1 - smooth_factor) * last_volume + smooth_factor * volume_scalar\n",
    "\n",
    "                    # ‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏ñ‡πâ‡∏≤‡∏ï‡πà‡∏≤‡∏á‡∏Å‡∏±‡∏ô‡∏ô‡πâ‡∏≠‡∏¢‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ\n",
    "                    if abs(volume.GetMasterVolumeLevelScalar() - last_volume) > 0.02:\n",
    "                        volume.SetMasterVolumeLevelScalar(last_volume, None)\n",
    "\n",
    "                    # ‡∏ß‡∏≤‡∏î‡πÄ‡∏™‡πâ‡∏ô‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏ô‡∏¥‡πâ‡∏ß‡πÇ‡∏õ‡πâ‡∏á‡∏Å‡∏±‡∏ö‡∏ä‡∏µ‡πâ\n",
    "                    cv2.line(img, (thumb_tip[0], thumb_tip[1]), (index_tip[0], index_tip[1]), (0, 255, 0), 3)\n",
    "\n",
    "                # ‡πÅ‡∏™‡∏î‡∏á‡∏£‡∏∞‡∏î‡∏±‡∏ö‡πÄ‡∏™‡∏µ‡∏¢‡∏á\n",
    "                volume_percent = int(last_volume * 100)\n",
    "                cv2.putText(img, f'Volume: {volume_percent}%', (50, 50),\n",
    "                            cv2.FONT_HERSHEY_COMPLEX, 1, (255, 0, 0), 2)\n",
    "\n",
    "                # ‡πÅ‡∏™‡∏î‡∏á‡πÅ‡∏ñ‡∏ö‡∏£‡∏∞‡∏î‡∏±‡∏ö‡πÄ‡∏™‡∏µ‡∏¢‡∏á\n",
    "                bar_height = int((1 - last_volume) * 300)\n",
    "                bar_color = (0, 255, 0) if last_volume > 0.5 else (0, 0, 255)  # ‡∏™‡∏µ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ß = ‡∏î‡∏±‡∏á, ‡πÅ‡∏î‡∏á = ‡πÄ‡∏ö‡∏≤\n",
    "                cv2.rectangle(img, (50, 100), (100, 400), (255, 0, 0), 3)  \n",
    "                cv2.rectangle(img, (50, 100 + bar_height), (100, 400), bar_color, -1)\n",
    "\n",
    "                # ‡πÅ‡∏™‡∏î‡∏á‡πÑ‡∏≠‡∏Ñ‡∏≠‡∏ô‡πÄ‡∏™‡∏µ‡∏¢‡∏á\n",
    "                cv2.putText(img, \"üîä\" if last_volume > 0.5 else \"üîà\", (120, 380), \n",
    "                            cv2.FONT_HERSHEY_COMPLEX, 1, bar_color, 2)\n",
    "\n",
    "            elif hand[\"type\"] == \"Left\" and len(hand[\"lmList\"]) >= 9:  # ‡∏°‡∏∑‡∏≠‡∏ã‡πâ‡∏≤‡∏¢ -> ‡∏Ñ‡∏ß‡∏ö‡∏Ñ‡∏∏‡∏°‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠\n",
    "                current_time = time.time()\n",
    "\n",
    "                if current_time - last_time > 1:  # ‡πÄ‡∏ä‡πá‡∏Ñ‡πÄ‡∏ß‡∏•‡∏≤‡∏´‡πà‡∏≤‡∏á‡∏Å‡∏±‡∏ô 1 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ\n",
    "                    if fingers == [0, 1, 0, 0, 0]:  # ‡∏ä‡∏µ‡πâ‡∏ô‡∏¥‡πâ‡∏ß‡∏°‡∏∑‡∏≠‡∏ã‡πâ‡∏≤‡∏¢‡πÑ‡∏õ‡∏ó‡∏≤‡∏á‡∏Ç‡∏ß‡∏≤ (‡πÄ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡∏Ñ‡∏•‡∏¥‡∏õ‡πÑ‡∏õ‡∏Ç‡πâ‡∏≤‡∏á‡∏´‡∏ô‡πâ‡∏≤ 5 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ)\n",
    "                        if current_time - last_move_time > move_interval:\n",
    "                            pyautogui.press('right')  # ‡πÄ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡∏Ñ‡∏•‡∏¥‡∏õ‡πÑ‡∏õ‡∏Ç‡πâ‡∏≤‡∏á‡∏´‡∏ô‡πâ‡∏≤ 5 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ\n",
    "                            last_move_time = current_time  # ‡∏£‡∏µ‡πÄ‡∏ã‡πá‡∏ï‡πÄ‡∏ß‡∏•‡∏≤‡∏Å‡∏≤‡∏£‡πÄ‡∏•‡∏∑‡πà‡∏≠‡∏ô\n",
    "\n",
    "                    elif fingers == [0, 1, 1, 0, 0]:  # ‡∏ä‡∏µ‡πâ 2 ‡∏ô‡∏¥‡πâ‡∏ß (‡∏ô‡∏¥‡πâ‡∏ß‡∏ä‡∏µ‡πâ, ‡∏ô‡∏¥‡πâ‡∏ß‡∏Å‡∏•‡∏≤‡∏á) (‡∏¢‡πâ‡∏≠‡∏ô‡∏Ñ‡∏•‡∏¥‡∏õ 5 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ)\n",
    "                        if current_time - last_move_time > move_interval:\n",
    "                            pyautogui.press('left')  # ‡πÄ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡∏Ñ‡∏•‡∏¥‡∏õ‡∏¢‡πâ‡∏≠‡∏ô‡∏Å‡∏•‡∏±‡∏ö 5 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ\n",
    "                            last_move_time = current_time  # ‡∏£‡∏µ‡πÄ‡∏ã‡πá‡∏ï‡πÄ‡∏ß‡∏•‡∏≤‡∏Å‡∏≤‡∏£‡πÄ‡∏•‡∏∑‡πà‡∏≠‡∏ô\n",
    "\n",
    "\n",
    "                    # ‡πÑ‡∏õ‡∏Ñ‡∏•‡∏¥‡∏õ‡∏ñ‡∏±‡∏î‡πÑ‡∏õ\n",
    "                    elif fingers == [0, 1, 1, 1, 1]:  # ‡∏ä‡∏µ‡πâ 4 ‡∏ô‡∏¥‡πâ‡∏ß (‡∏ä‡∏µ‡πâ‡∏ô‡∏¥‡πâ‡∏ß, ‡∏ô‡∏¥‡πâ‡∏ß‡∏Å‡∏•‡∏≤‡∏á, ‡∏ô‡∏¥‡πâ‡∏ß‡∏ô‡∏≤‡∏á, ‡∏ô‡∏¥‡πâ‡∏ß‡∏Å‡πâ‡∏≠‡∏¢)\n",
    "                        if current_time - last_next_time > next_interval:  # 5 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ\n",
    "                            pyautogui.hotkey('shift', 'n')  # ‡πÉ‡∏ä‡πâ shift + n ‡πÑ‡∏õ‡∏Ñ‡∏•‡∏¥‡∏õ‡∏ñ‡∏±‡∏î‡πÑ‡∏õ\n",
    "                            last_next_time = current_time  # ‡∏£‡∏µ‡πÄ‡∏ã‡πá‡∏ï‡πÄ‡∏ß‡∏•‡∏≤‡∏Å‡∏≤‡∏£‡πÑ‡∏õ‡∏Ñ‡∏•‡∏¥‡∏õ‡∏ñ‡∏±‡∏î‡πÑ‡∏õ\n",
    "\n",
    "\n",
    "                    elif fingers == [0, 0, 0, 0, 1]:  # ‡∏Å‡∏≥‡∏°‡∏∑‡∏≠ = ‡∏´‡∏¢‡∏∏‡∏î‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠\n",
    "                        pyautogui.press('space')  \n",
    "                        last_time = current_time  # ‡∏£‡∏µ‡πÄ‡∏ã‡πá‡∏ï‡πÄ‡∏ß‡∏•‡∏≤\n",
    "\n",
    "                    elif fingers == [1, 1, 1, 1, 1]:  # ‡πÅ‡∏ö‡∏°‡∏∑‡∏≠ 5 ‡∏ô‡∏¥‡πâ‡∏ß = ‡πÄ‡∏•‡πà‡∏ô‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠‡∏ï‡πà‡∏≠\n",
    "                        pyautogui.press('space')  \n",
    "                        last_time = current_time  # ‡∏£‡∏µ‡πÄ‡∏ã‡πá‡∏ï‡πÄ‡∏ß‡∏•‡∏≤\n",
    "\n",
    "    img = cv2.resize(img, (960, 720))\n",
    "    cv2.imshow(\"image\", img)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "444cf9cc-6f79-42e1-a348-d03db1bea4f6",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cvzone'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcvzone\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mHandTrackingModule\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HandDetector\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmath\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mctypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cast, POINTER\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'cvzone'"
     ]
    }
   ],
   "source": [
    " import cv2\n",
    "from cvzone.HandTrackingModule import HandDetector\n",
    "import math\n",
    "from ctypes import cast, POINTER\n",
    "from comtypes import CLSCTX_ALL\n",
    "from pycaw.pycaw import AudioUtilities, IAudioEndpointVolume\n",
    "import pyautogui  # ‡πÉ‡∏ä‡πâ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ñ‡∏ß‡∏ö‡∏Ñ‡∏∏‡∏°‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠\n",
    "import time\n",
    "\n",
    "# ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏Å‡∏•‡πâ‡∏≠‡∏á\n",
    "cap = cv2.VideoCapture(0)\n",
    "detector = HandDetector(detectionCon=0.8)  # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö\n",
    "\n",
    "# ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏£‡∏∞‡∏ö‡∏ö‡πÄ‡∏™‡∏µ‡∏¢‡∏á\n",
    "devices = AudioUtilities.GetSpeakers()\n",
    "interface = devices.Activate(IAudioEndpointVolume._iid_, CLSCTX_ALL, None)\n",
    "volume = cast(interface, POINTER(IAudioEndpointVolume))\n",
    "\n",
    "# ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏Ñ‡πà‡∏≤‡∏ï‡πà‡∏≥‡∏™‡∏∏‡∏î-‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î‡∏Ç‡∏≠‡∏á‡∏£‡∏∞‡∏¢‡∏∞‡∏°‡∏∑‡∏≠\n",
    "min_distance = 20\n",
    "max_distance = 180\n",
    "adjusting_volume = False  # ‡πÄ‡∏ä‡πá‡∏Ñ‡∏ß‡πà‡∏≤‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏õ‡∏£‡∏±‡∏ö‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏≠‡∏¢‡∏π‡πà‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà\n",
    "last_volume = volume.GetMasterVolumeLevelScalar()  # ‡πÄ‡∏Å‡πá‡∏ö‡∏£‡∏∞‡∏î‡∏±‡∏ö‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î\n",
    "\n",
    "# ‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£‡πÉ‡∏´‡∏°‡πà‡πÄ‡∏ä‡πá‡∏Ñ‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏Å‡∏≤‡∏£‡∏Å‡∏î\n",
    "last_action = None\n",
    "last_time = time.time()  # ‡πÉ‡∏ä‡πâ‡∏à‡∏±‡∏ö‡πÄ‡∏ß‡∏•‡∏≤‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô‡∏Å‡∏≤‡∏£‡∏Å‡∏î‡∏ã‡πâ‡∏≥\n",
    "last_move_time = time.time()  # ‡∏à‡∏±‡∏ö‡πÄ‡∏ß‡∏•‡∏≤‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡∏Ñ‡∏•‡∏¥‡∏õ\n",
    "last_skip_time = time.time()  # ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏à‡∏±‡∏ö‡πÄ‡∏ß‡∏•‡∏≤‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏Ç‡πâ‡∏≤‡∏°‡πÇ‡∏Ü‡∏©‡∏ì‡∏≤\n",
    "last_next_time = time.time()  # ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏à‡∏±‡∏ö‡πÄ‡∏ß‡∏•‡∏≤‡πÑ‡∏õ‡∏Ñ‡∏•‡∏¥‡∏õ‡∏ñ‡∏±‡∏î‡πÑ‡∏õ\n",
    "\n",
    "# ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡∏Ñ‡∏•‡∏¥‡∏õ\n",
    "move_interval = 1  # 1 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡∏Ñ‡∏•‡∏¥‡∏õ\n",
    "move_duration = 5  # 5 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡∏Ñ‡∏•‡∏¥‡∏õ\n",
    "skip_interval = 5  # 5 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ‡∏´‡∏•‡∏±‡∏á‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≤‡∏°‡πÇ‡∏Ü‡∏©‡∏ì‡∏≤\n",
    "next_interval = 5  # 5 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ‡∏´‡∏•‡∏±‡∏á‡∏à‡∏≤‡∏Å‡πÑ‡∏õ‡∏Ñ‡∏•‡∏¥‡∏õ‡∏ñ‡∏±‡∏î‡πÑ‡∏õ\n",
    "\n",
    "while True:\n",
    "    success, img = cap.read()\n",
    "    hands, img = detector.findHands(img)\n",
    "\n",
    "    if hands:\n",
    "        for hand in hands:\n",
    "            fingers = detector.fingersUp(hand)  # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ô‡∏¥‡πâ‡∏ß‡∏ó‡∏µ‡πà‡∏¢‡∏Å\n",
    "\n",
    "            if hand[\"type\"] == \"Right\" and len(hand[\"lmList\"]) >= 9:  # ‡∏°‡∏∑‡∏≠‡∏Ç‡∏ß‡∏≤ -> ‡∏Ñ‡∏ß‡∏ö‡∏Ñ‡∏∏‡∏°‡πÄ‡∏™‡∏µ‡∏¢‡∏á\n",
    "                if fingers == [1, 1, 1, 1, 1]:  # ‡∏Å‡∏≤‡∏á‡∏°‡∏∑‡∏≠ 5 ‡∏ô‡∏¥‡πâ‡∏ß -> ‡∏´‡∏¢‡∏∏‡∏î‡∏ó‡∏µ‡πà‡∏£‡∏∞‡∏î‡∏±‡∏ö‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÄ‡∏î‡∏¥‡∏°\n",
    "                    adjusting_volume = False  \n",
    "\n",
    "                elif fingers == [1, 1, 0, 0, 0]:  # ‡∏ä‡∏π‡πÅ‡∏Ñ‡πà‡πÇ‡∏õ‡πâ‡∏á‡∏Å‡∏±‡∏ö‡∏ä‡∏µ‡πâ -> ‡∏õ‡∏£‡∏±‡∏ö‡πÄ‡∏™‡∏µ‡∏¢‡∏á\n",
    "                    adjusting_volume = True\n",
    "                    thumb_tip = hand[\"lmList\"][4]\n",
    "                    index_tip = hand[\"lmList\"][8]\n",
    "                    \n",
    "                    # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏£‡∏∞‡∏¢‡∏∞‡∏´‡πà‡∏≤‡∏á‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏ô‡∏¥‡πâ‡∏ß‡πÇ‡∏õ‡πâ‡∏á‡πÅ‡∏•‡∏∞‡∏ô‡∏¥‡πâ‡∏ß‡∏ä‡∏µ‡πâ\n",
    "                    distance_x = abs(thumb_tip[0] - index_tip[0])\n",
    "                    distance_y = abs(thumb_tip[1] - index_tip[1])\n",
    "                    distance = math.hypot(distance_x, distance_y)\n",
    "                    distance = max(min_distance, min(distance, max_distance))\n",
    "\n",
    "                    volume_scalar = (distance - min_distance) / (max_distance - min_distance)\n",
    "\n",
    "                    # ‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏ô‡∏∏‡πà‡∏°‡∏ô‡∏ß‡∏•‡∏Ç‡∏∂‡πâ‡∏ô\n",
    "                    smooth_factor = 0.2  \n",
    "                    last_volume = (1 - smooth_factor) * last_volume + smooth_factor * volume_scalar\n",
    "\n",
    "                    # ‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏ñ‡πâ‡∏≤‡∏ï‡πà‡∏≤‡∏á‡∏Å‡∏±‡∏ô‡∏ô‡πâ‡∏≠‡∏¢‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ\n",
    "                    if abs(volume.GetMasterVolumeLevelScalar() - last_volume) > 0.02:\n",
    "                        volume.SetMasterVolumeLevelScalar(last_volume, None)\n",
    "\n",
    "                    # ‡∏ß‡∏≤‡∏î‡πÄ‡∏™‡πâ‡∏ô‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏ô‡∏¥‡πâ‡∏ß‡πÇ‡∏õ‡πâ‡∏á‡∏Å‡∏±‡∏ö‡∏ä‡∏µ‡πâ\n",
    "                    cv2.line(img, (thumb_tip[0], thumb_tip[1]), (index_tip[0], index_tip[1]), (0, 255, 0), 3)\n",
    "\n",
    "                # ‡πÅ‡∏™‡∏î‡∏á‡∏£‡∏∞‡∏î‡∏±‡∏ö‡πÄ‡∏™‡∏µ‡∏¢‡∏á\n",
    "                volume_percent = int(last_volume * 100)\n",
    "                cv2.putText(img, f'Volume: {volume_percent}%', (50, 50),\n",
    "                            cv2.FONT_HERSHEY_COMPLEX, 1, (255, 0, 0), 2)\n",
    "\n",
    "                # ‡πÅ‡∏™‡∏î‡∏á‡πÅ‡∏ñ‡∏ö‡∏£‡∏∞‡∏î‡∏±‡∏ö‡πÄ‡∏™‡∏µ‡∏¢‡∏á\n",
    "                bar_height = int((1 - last_volume) * 300)\n",
    "                bar_color = (0, 255, 0) if last_volume > 0.5 else (0, 0, 255)  # ‡∏™‡∏µ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ß = ‡∏î‡∏±‡∏á, ‡πÅ‡∏î‡∏á = ‡πÄ‡∏ö‡∏≤\n",
    "                cv2.rectangle(img, (50, 100), (100, 400), (255, 0, 0), 3)  \n",
    "                cv2.rectangle(img, (50, 100 + bar_height), (100, 400), bar_color, -1)\n",
    "\n",
    "                # ‡πÅ‡∏™‡∏î‡∏á‡πÑ‡∏≠‡∏Ñ‡∏≠‡∏ô‡πÄ‡∏™‡∏µ‡∏¢‡∏á\n",
    "                cv2.putText(img, \"üîä\" if last_volume > 0.5 else \"üîà\", (120, 380), \n",
    "                            cv2.FONT_HERSHEY_COMPLEX, 1, bar_color, 2)\n",
    "\n",
    "            elif hand[\"type\"] == \"Left\" and len(hand[\"lmList\"]) >= 9:  # ‡∏°‡∏∑‡∏≠‡∏ã‡πâ‡∏≤‡∏¢ -> ‡∏Ñ‡∏ß‡∏ö‡∏Ñ‡∏∏‡∏°‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠\n",
    "                current_time = time.time()\n",
    "\n",
    "                if current_time - last_time > 1:  # ‡πÄ‡∏ä‡πá‡∏Ñ‡πÄ‡∏ß‡∏•‡∏≤‡∏´‡πà‡∏≤‡∏á‡∏Å‡∏±‡∏ô 1 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ\n",
    "                    if fingers == [0, 1, 0, 0, 0]:  # ‡∏ä‡∏µ‡πâ‡∏ô‡∏¥‡πâ‡∏ß‡∏°‡∏∑‡∏≠‡∏ã‡πâ‡∏≤‡∏¢‡πÑ‡∏õ‡∏ó‡∏≤‡∏á‡∏Ç‡∏ß‡∏≤ (‡πÄ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡∏Ñ‡∏•‡∏¥‡∏õ‡πÑ‡∏õ‡∏Ç‡πâ‡∏≤‡∏á‡∏´‡∏ô‡πâ‡∏≤ 5 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ)\n",
    "                        if current_time - last_move_time > move_interval:\n",
    "                            pyautogui.press('right')  # ‡πÄ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡∏Ñ‡∏•‡∏¥‡∏õ‡πÑ‡∏õ‡∏Ç‡πâ‡∏≤‡∏á‡∏´‡∏ô‡πâ‡∏≤ 5 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ\n",
    "                            last_move_time = current_time  # ‡∏£‡∏µ‡πÄ‡∏ã‡πá‡∏ï‡πÄ‡∏ß‡∏•‡∏≤‡∏Å‡∏≤‡∏£‡πÄ‡∏•‡∏∑‡πà‡∏≠‡∏ô\n",
    "\n",
    "                    elif fingers == [0, 1, 1, 0, 0]:  # ‡∏ä‡∏µ‡πâ 2 ‡∏ô‡∏¥‡πâ‡∏ß (‡∏ô‡∏¥‡πâ‡∏ß‡∏ä‡∏µ‡πâ, ‡∏ô‡∏¥‡πâ‡∏ß‡∏Å‡∏•‡∏≤‡∏á) (‡∏¢‡πâ‡∏≠‡∏ô‡∏Ñ‡∏•‡∏¥‡∏õ 5 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ)\n",
    "                        if current_time - last_move_time > move_interval:\n",
    "                            pyautogui.press('left')  # ‡πÄ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡∏Ñ‡∏•‡∏¥‡∏õ‡∏¢‡πâ‡∏≠‡∏ô‡∏Å‡∏•‡∏±‡∏ö 5 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ\n",
    "                            last_move_time = current_time  # ‡∏£‡∏µ‡πÄ‡∏ã‡πá‡∏ï‡πÄ‡∏ß‡∏•‡∏≤‡∏Å‡∏≤‡∏£‡πÄ‡∏•‡∏∑‡πà‡∏≠‡∏ô\n",
    "\n",
    "\n",
    "                    # ‡πÑ‡∏õ‡∏Ñ‡∏•‡∏¥‡∏õ‡∏ñ‡∏±‡∏î‡πÑ‡∏õ\n",
    "                    elif fingers == [0, 1, 1, 1, 1]:  # ‡∏ä‡∏µ‡πâ 4 ‡∏ô‡∏¥‡πâ‡∏ß (‡∏ä‡∏µ‡πâ‡∏ô‡∏¥‡πâ‡∏ß, ‡∏ô‡∏¥‡πâ‡∏ß‡∏Å‡∏•‡∏≤‡∏á, ‡∏ô‡∏¥‡πâ‡∏ß‡∏ô‡∏≤‡∏á, ‡∏ô‡∏¥‡πâ‡∏ß‡∏Å‡πâ‡∏≠‡∏¢)\n",
    "                        if current_time - last_next_time > next_interval:  # 5 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ\n",
    "                            pyautogui.hotkey('shift', 'n')  # ‡πÉ‡∏ä‡πâ shift + n ‡πÑ‡∏õ‡∏Ñ‡∏•‡∏¥‡∏õ‡∏ñ‡∏±‡∏î‡πÑ‡∏õ\n",
    "                            last_next_time = current_time  # ‡∏£‡∏µ‡πÄ‡∏ã‡πá‡∏ï‡πÄ‡∏ß‡∏•‡∏≤‡∏Å‡∏≤‡∏£‡πÑ‡∏õ‡∏Ñ‡∏•‡∏¥‡∏õ‡∏ñ‡∏±‡∏î‡πÑ‡∏õ\n",
    "\n",
    "\n",
    "                    elif fingers == [0, 0, 0, 0, 1]:  # ‡∏Å‡∏≥‡∏°‡∏∑‡∏≠ = ‡∏´‡∏¢‡∏∏‡∏î‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠\n",
    "                        pyautogui.press('space')  \n",
    "                        last_time = current_time  # ‡∏£‡∏µ‡πÄ‡∏ã‡πá‡∏ï‡πÄ‡∏ß‡∏•‡∏≤\n",
    "\n",
    "                    elif fingers == [1, 1, 1, 1, 1]:  # ‡πÅ‡∏ö‡∏°‡∏∑‡∏≠ 5 ‡∏ô‡∏¥‡πâ‡∏ß = ‡πÄ‡∏•‡πà‡∏ô‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠‡∏ï‡πà‡∏≠\n",
    "                        pyautogui.press('space')  \n",
    "                        last_time = current_time  # ‡∏£‡∏µ‡πÄ‡∏ã‡πá‡∏ï‡πÄ‡∏ß‡∏•‡∏≤\n",
    "\n",
    "    img = cv2.resize(img, (960, 720))\n",
    "    cv2.imshow(\"image\", img)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e1b8d89f-f77f-4073-8912-055e493bfa9e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'mediapipe'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcvzone\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mHandTrackingModule\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HandDetector\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\cvzone\\HandTrackingModule.py:10\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmath\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmediapipe\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmp\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mHandDetector\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m    Finds Hands using the mediapipe library. Exports the landmarks\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;124;03m    in pixel format. Adds extra functionalities like finding how\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;124;03m    many fingers are up or the distance between two fingers. Also\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;124;03m    provides bounding box info of the hand found.\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'mediapipe'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from cvzone.HandTrackingModule import HandDetector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e330c0f4-3c36-4802-846e-788cc25a76e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from cvzone.HandTrackingModule import HandDetector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "38489567-b7b7-4566-a55f-ef30c2c24d06",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'comtypes'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmath\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mctypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cast, POINTER\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcomtypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CLSCTX_ALL\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpycaw\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpycaw\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AudioUtilities, IAudioEndpointVolume\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpyautogui\u001b[39;00m  \u001b[38;5;66;03m# ‡πÉ‡∏ä‡πâ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ñ‡∏ß‡∏ö‡∏Ñ‡∏∏‡∏°‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'comtypes'"
     ]
    }
   ],
   "source": [
    " import cv2\n",
    "from cvzone.HandTrackingModule import HandDetector\n",
    "import math\n",
    "from ctypes import cast, POINTER\n",
    "from comtypes import CLSCTX_ALL\n",
    "from pycaw.pycaw import AudioUtilities, IAudioEndpointVolume\n",
    "import pyautogui  # ‡πÉ‡∏ä‡πâ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ñ‡∏ß‡∏ö‡∏Ñ‡∏∏‡∏°‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠\n",
    "import time\n",
    "\n",
    "# ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏Å‡∏•‡πâ‡∏≠‡∏á\n",
    "cap = cv2.VideoCapture(0)\n",
    "detector = HandDetector(detectionCon=0.8)  # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö\n",
    "\n",
    "# ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏£‡∏∞‡∏ö‡∏ö‡πÄ‡∏™‡∏µ‡∏¢‡∏á\n",
    "devices = AudioUtilities.GetSpeakers()\n",
    "interface = devices.Activate(IAudioEndpointVolume._iid_, CLSCTX_ALL, None)\n",
    "volume = cast(interface, POINTER(IAudioEndpointVolume))\n",
    "\n",
    "# ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏Ñ‡πà‡∏≤‡∏ï‡πà‡∏≥‡∏™‡∏∏‡∏î-‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î‡∏Ç‡∏≠‡∏á‡∏£‡∏∞‡∏¢‡∏∞‡∏°‡∏∑‡∏≠\n",
    "min_distance = 20\n",
    "max_distance = 180\n",
    "adjusting_volume = False  # ‡πÄ‡∏ä‡πá‡∏Ñ‡∏ß‡πà‡∏≤‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏õ‡∏£‡∏±‡∏ö‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏≠‡∏¢‡∏π‡πà‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà\n",
    "last_volume = volume.GetMasterVolumeLevelScalar()  # ‡πÄ‡∏Å‡πá‡∏ö‡∏£‡∏∞‡∏î‡∏±‡∏ö‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î\n",
    "\n",
    "# ‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£‡πÉ‡∏´‡∏°‡πà‡πÄ‡∏ä‡πá‡∏Ñ‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏Å‡∏≤‡∏£‡∏Å‡∏î\n",
    "last_action = None\n",
    "last_time = time.time()  # ‡πÉ‡∏ä‡πâ‡∏à‡∏±‡∏ö‡πÄ‡∏ß‡∏•‡∏≤‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô‡∏Å‡∏≤‡∏£‡∏Å‡∏î‡∏ã‡πâ‡∏≥\n",
    "last_move_time = time.time()  # ‡∏à‡∏±‡∏ö‡πÄ‡∏ß‡∏•‡∏≤‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡∏Ñ‡∏•‡∏¥‡∏õ\n",
    "last_skip_time = time.time()  # ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏à‡∏±‡∏ö‡πÄ‡∏ß‡∏•‡∏≤‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏Ç‡πâ‡∏≤‡∏°‡πÇ‡∏Ü‡∏©‡∏ì‡∏≤\n",
    "last_next_time = time.time()  # ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏à‡∏±‡∏ö‡πÄ‡∏ß‡∏•‡∏≤‡πÑ‡∏õ‡∏Ñ‡∏•‡∏¥‡∏õ‡∏ñ‡∏±‡∏î‡πÑ‡∏õ\n",
    "\n",
    "# ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡∏Ñ‡∏•‡∏¥‡∏õ\n",
    "move_interval = 1  # 1 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡∏Ñ‡∏•‡∏¥‡∏õ\n",
    "move_duration = 5  # 5 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡∏Ñ‡∏•‡∏¥‡∏õ\n",
    "skip_interval = 5  # 5 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ‡∏´‡∏•‡∏±‡∏á‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≤‡∏°‡πÇ‡∏Ü‡∏©‡∏ì‡∏≤\n",
    "next_interval = 5  # 5 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ‡∏´‡∏•‡∏±‡∏á‡∏à‡∏≤‡∏Å‡πÑ‡∏õ‡∏Ñ‡∏•‡∏¥‡∏õ‡∏ñ‡∏±‡∏î‡πÑ‡∏õ\n",
    "\n",
    "while True:\n",
    "    success, img = cap.read()\n",
    "    hands, img = detector.findHands(img)\n",
    "\n",
    "    if hands:\n",
    "        for hand in hands:\n",
    "            fingers = detector.fingersUp(hand)  # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ô‡∏¥‡πâ‡∏ß‡∏ó‡∏µ‡πà‡∏¢‡∏Å\n",
    "\n",
    "            if hand[\"type\"] == \"Right\" and len(hand[\"lmList\"]) >= 9:  # ‡∏°‡∏∑‡∏≠‡∏Ç‡∏ß‡∏≤ -> ‡∏Ñ‡∏ß‡∏ö‡∏Ñ‡∏∏‡∏°‡πÄ‡∏™‡∏µ‡∏¢‡∏á\n",
    "                if fingers == [1, 1, 1, 1, 1]:  # ‡∏Å‡∏≤‡∏á‡∏°‡∏∑‡∏≠ 5 ‡∏ô‡∏¥‡πâ‡∏ß -> ‡∏´‡∏¢‡∏∏‡∏î‡∏ó‡∏µ‡πà‡∏£‡∏∞‡∏î‡∏±‡∏ö‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÄ‡∏î‡∏¥‡∏°\n",
    "                    adjusting_volume = False  \n",
    "\n",
    "                elif fingers == [1, 1, 0, 0, 0]:  # ‡∏ä‡∏π‡πÅ‡∏Ñ‡πà‡πÇ‡∏õ‡πâ‡∏á‡∏Å‡∏±‡∏ö‡∏ä‡∏µ‡πâ -> ‡∏õ‡∏£‡∏±‡∏ö‡πÄ‡∏™‡∏µ‡∏¢‡∏á\n",
    "                    adjusting_volume = True\n",
    "                    thumb_tip = hand[\"lmList\"][4]\n",
    "                    index_tip = hand[\"lmList\"][8]\n",
    "                    \n",
    "                    # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏£‡∏∞‡∏¢‡∏∞‡∏´‡πà‡∏≤‡∏á‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏ô‡∏¥‡πâ‡∏ß‡πÇ‡∏õ‡πâ‡∏á‡πÅ‡∏•‡∏∞‡∏ô‡∏¥‡πâ‡∏ß‡∏ä‡∏µ‡πâ\n",
    "                    distance_x = abs(thumb_tip[0] - index_tip[0])\n",
    "                    distance_y = abs(thumb_tip[1] - index_tip[1])\n",
    "                    distance = math.hypot(distance_x, distance_y)\n",
    "                    distance = max(min_distance, min(distance, max_distance))\n",
    "\n",
    "                    volume_scalar = (distance - min_distance) / (max_distance - min_distance)\n",
    "\n",
    "                    # ‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏ô‡∏∏‡πà‡∏°‡∏ô‡∏ß‡∏•‡∏Ç‡∏∂‡πâ‡∏ô\n",
    "                    smooth_factor = 0.2  \n",
    "                    last_volume = (1 - smooth_factor) * last_volume + smooth_factor * volume_scalar\n",
    "\n",
    "                    # ‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏ñ‡πâ‡∏≤‡∏ï‡πà‡∏≤‡∏á‡∏Å‡∏±‡∏ô‡∏ô‡πâ‡∏≠‡∏¢‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ\n",
    "                    if abs(volume.GetMasterVolumeLevelScalar() - last_volume) > 0.02:\n",
    "                        volume.SetMasterVolumeLevelScalar(last_volume, None)\n",
    "\n",
    "                    # ‡∏ß‡∏≤‡∏î‡πÄ‡∏™‡πâ‡∏ô‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏ô‡∏¥‡πâ‡∏ß‡πÇ‡∏õ‡πâ‡∏á‡∏Å‡∏±‡∏ö‡∏ä‡∏µ‡πâ\n",
    "                    cv2.line(img, (thumb_tip[0], thumb_tip[1]), (index_tip[0], index_tip[1]), (0, 255, 0), 3)\n",
    "\n",
    "                # ‡πÅ‡∏™‡∏î‡∏á‡∏£‡∏∞‡∏î‡∏±‡∏ö‡πÄ‡∏™‡∏µ‡∏¢‡∏á\n",
    "                volume_percent = int(last_volume * 100)\n",
    "                cv2.putText(img, f'Volume: {volume_percent}%', (50, 50),\n",
    "                            cv2.FONT_HERSHEY_COMPLEX, 1, (255, 0, 0), 2)\n",
    "\n",
    "                # ‡πÅ‡∏™‡∏î‡∏á‡πÅ‡∏ñ‡∏ö‡∏£‡∏∞‡∏î‡∏±‡∏ö‡πÄ‡∏™‡∏µ‡∏¢‡∏á\n",
    "                bar_height = int((1 - last_volume) * 300)\n",
    "                bar_color = (0, 255, 0) if last_volume > 0.5 else (0, 0, 255)  # ‡∏™‡∏µ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ß = ‡∏î‡∏±‡∏á, ‡πÅ‡∏î‡∏á = ‡πÄ‡∏ö‡∏≤\n",
    "                cv2.rectangle(img, (50, 100), (100, 400), (255, 0, 0), 3)  \n",
    "                cv2.rectangle(img, (50, 100 + bar_height), (100, 400), bar_color, -1)\n",
    "\n",
    "                # ‡πÅ‡∏™‡∏î‡∏á‡πÑ‡∏≠‡∏Ñ‡∏≠‡∏ô‡πÄ‡∏™‡∏µ‡∏¢‡∏á\n",
    "                cv2.putText(img, \"üîä\" if last_volume > 0.5 else \"üîà\", (120, 380), \n",
    "                            cv2.FONT_HERSHEY_COMPLEX, 1, bar_color, 2)\n",
    "\n",
    "            elif hand[\"type\"] == \"Left\" and len(hand[\"lmList\"]) >= 9:  # ‡∏°‡∏∑‡∏≠‡∏ã‡πâ‡∏≤‡∏¢ -> ‡∏Ñ‡∏ß‡∏ö‡∏Ñ‡∏∏‡∏°‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠\n",
    "                current_time = time.time()\n",
    "\n",
    "                if current_time - last_time > 1:  # ‡πÄ‡∏ä‡πá‡∏Ñ‡πÄ‡∏ß‡∏•‡∏≤‡∏´‡πà‡∏≤‡∏á‡∏Å‡∏±‡∏ô 1 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ\n",
    "                    if fingers == [0, 1, 0, 0, 0]:  # ‡∏ä‡∏µ‡πâ‡∏ô‡∏¥‡πâ‡∏ß‡∏°‡∏∑‡∏≠‡∏ã‡πâ‡∏≤‡∏¢‡πÑ‡∏õ‡∏ó‡∏≤‡∏á‡∏Ç‡∏ß‡∏≤ (‡πÄ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡∏Ñ‡∏•‡∏¥‡∏õ‡πÑ‡∏õ‡∏Ç‡πâ‡∏≤‡∏á‡∏´‡∏ô‡πâ‡∏≤ 5 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ)\n",
    "                        if current_time - last_move_time > move_interval:\n",
    "                            pyautogui.press('right')  # ‡πÄ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡∏Ñ‡∏•‡∏¥‡∏õ‡πÑ‡∏õ‡∏Ç‡πâ‡∏≤‡∏á‡∏´‡∏ô‡πâ‡∏≤ 5 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ\n",
    "                            last_move_time = current_time  # ‡∏£‡∏µ‡πÄ‡∏ã‡πá‡∏ï‡πÄ‡∏ß‡∏•‡∏≤‡∏Å‡∏≤‡∏£‡πÄ‡∏•‡∏∑‡πà‡∏≠‡∏ô\n",
    "\n",
    "                    elif fingers == [0, 1, 1, 0, 0]:  # ‡∏ä‡∏µ‡πâ 2 ‡∏ô‡∏¥‡πâ‡∏ß (‡∏ô‡∏¥‡πâ‡∏ß‡∏ä‡∏µ‡πâ, ‡∏ô‡∏¥‡πâ‡∏ß‡∏Å‡∏•‡∏≤‡∏á) (‡∏¢‡πâ‡∏≠‡∏ô‡∏Ñ‡∏•‡∏¥‡∏õ 5 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ)\n",
    "                        if current_time - last_move_time > move_interval:\n",
    "                            pyautogui.press('left')  # ‡πÄ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡∏Ñ‡∏•‡∏¥‡∏õ‡∏¢‡πâ‡∏≠‡∏ô‡∏Å‡∏•‡∏±‡∏ö 5 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ\n",
    "                            last_move_time = current_time  # ‡∏£‡∏µ‡πÄ‡∏ã‡πá‡∏ï‡πÄ‡∏ß‡∏•‡∏≤‡∏Å‡∏≤‡∏£‡πÄ‡∏•‡∏∑‡πà‡∏≠‡∏ô\n",
    "\n",
    "\n",
    "                    # ‡πÑ‡∏õ‡∏Ñ‡∏•‡∏¥‡∏õ‡∏ñ‡∏±‡∏î‡πÑ‡∏õ\n",
    "                    elif fingers == [0, 1, 1, 1, 1]:  # ‡∏ä‡∏µ‡πâ 4 ‡∏ô‡∏¥‡πâ‡∏ß (‡∏ä‡∏µ‡πâ‡∏ô‡∏¥‡πâ‡∏ß, ‡∏ô‡∏¥‡πâ‡∏ß‡∏Å‡∏•‡∏≤‡∏á, ‡∏ô‡∏¥‡πâ‡∏ß‡∏ô‡∏≤‡∏á, ‡∏ô‡∏¥‡πâ‡∏ß‡∏Å‡πâ‡∏≠‡∏¢)\n",
    "                        if current_time - last_next_time > next_interval:  # 5 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ\n",
    "                            pyautogui.hotkey('shift', 'n')  # ‡πÉ‡∏ä‡πâ shift + n ‡πÑ‡∏õ‡∏Ñ‡∏•‡∏¥‡∏õ‡∏ñ‡∏±‡∏î‡πÑ‡∏õ\n",
    "                            last_next_time = current_time  # ‡∏£‡∏µ‡πÄ‡∏ã‡πá‡∏ï‡πÄ‡∏ß‡∏•‡∏≤‡∏Å‡∏≤‡∏£‡πÑ‡∏õ‡∏Ñ‡∏•‡∏¥‡∏õ‡∏ñ‡∏±‡∏î‡πÑ‡∏õ\n",
    "\n",
    "\n",
    "                    elif fingers == [0, 0, 0, 0, 1]:  # ‡∏Å‡∏≥‡∏°‡∏∑‡∏≠ = ‡∏´‡∏¢‡∏∏‡∏î‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠\n",
    "                        pyautogui.press('space')  \n",
    "                        last_time = current_time  # ‡∏£‡∏µ‡πÄ‡∏ã‡πá‡∏ï‡πÄ‡∏ß‡∏•‡∏≤\n",
    "\n",
    "                    elif fingers == [1, 1, 1, 1, 1]:  # ‡πÅ‡∏ö‡∏°‡∏∑‡∏≠ 5 ‡∏ô‡∏¥‡πâ‡∏ß = ‡πÄ‡∏•‡πà‡∏ô‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠‡∏ï‡πà‡∏≠\n",
    "                        pyautogui.press('space')  \n",
    "                        last_time = current_time  # ‡∏£‡∏µ‡πÄ‡∏ã‡πá‡∏ï‡πÄ‡∏ß‡∏•‡∏≤\n",
    "\n",
    "    img = cv2.resize(img, (960, 720))\n",
    "    cv2.imshow(\"image\", img)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5de184c6-9db8-47fe-aacf-c0b2d8100dfa",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pycaw'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[39], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mctypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cast, POINTER\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcomtypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CLSCTX_ALL\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpycaw\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpycaw\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AudioUtilities, IAudioEndpointVolume\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpyautogui\u001b[39;00m  \u001b[38;5;66;03m# ‡πÉ‡∏ä‡πâ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ñ‡∏ß‡∏ö‡∏Ñ‡∏∏‡∏°‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pycaw'"
     ]
    }
   ],
   "source": [
    " import cv2\n",
    "from cvzone.HandTrackingModule import HandDetector\n",
    "import math\n",
    "from ctypes import cast, POINTER\n",
    "from comtypes import CLSCTX_ALL\n",
    "from pycaw.pycaw import AudioUtilities, IAudioEndpointVolume\n",
    "import pyautogui  # ‡πÉ‡∏ä‡πâ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ñ‡∏ß‡∏ö‡∏Ñ‡∏∏‡∏°‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠\n",
    "import time\n",
    "\n",
    "# ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏Å‡∏•‡πâ‡∏≠‡∏á\n",
    "cap = cv2.VideoCapture(0)\n",
    "detector = HandDetector(detectionCon=0.8)  # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö\n",
    "\n",
    "# ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏£‡∏∞‡∏ö‡∏ö‡πÄ‡∏™‡∏µ‡∏¢‡∏á\n",
    "devices = AudioUtilities.GetSpeakers()\n",
    "interface = devices.Activate(IAudioEndpointVolume._iid_, CLSCTX_ALL, None)\n",
    "volume = cast(interface, POINTER(IAudioEndpointVolume))\n",
    "\n",
    "# ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏Ñ‡πà‡∏≤‡∏ï‡πà‡∏≥‡∏™‡∏∏‡∏î-‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î‡∏Ç‡∏≠‡∏á‡∏£‡∏∞‡∏¢‡∏∞‡∏°‡∏∑‡∏≠\n",
    "min_distance = 20\n",
    "max_distance = 180\n",
    "adjusting_volume = False  # ‡πÄ‡∏ä‡πá‡∏Ñ‡∏ß‡πà‡∏≤‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏õ‡∏£‡∏±‡∏ö‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏≠‡∏¢‡∏π‡πà‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà\n",
    "last_volume = volume.GetMasterVolumeLevelScalar()  # ‡πÄ‡∏Å‡πá‡∏ö‡∏£‡∏∞‡∏î‡∏±‡∏ö‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î\n",
    "\n",
    "# ‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£‡πÉ‡∏´‡∏°‡πà‡πÄ‡∏ä‡πá‡∏Ñ‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏Å‡∏≤‡∏£‡∏Å‡∏î\n",
    "last_action = None\n",
    "last_time = time.time()  # ‡πÉ‡∏ä‡πâ‡∏à‡∏±‡∏ö‡πÄ‡∏ß‡∏•‡∏≤‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô‡∏Å‡∏≤‡∏£‡∏Å‡∏î‡∏ã‡πâ‡∏≥\n",
    "last_move_time = time.time()  # ‡∏à‡∏±‡∏ö‡πÄ‡∏ß‡∏•‡∏≤‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡∏Ñ‡∏•‡∏¥‡∏õ\n",
    "last_skip_time = time.time()  # ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏à‡∏±‡∏ö‡πÄ‡∏ß‡∏•‡∏≤‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏Ç‡πâ‡∏≤‡∏°‡πÇ‡∏Ü‡∏©‡∏ì‡∏≤\n",
    "last_next_time = time.time()  # ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏à‡∏±‡∏ö‡πÄ‡∏ß‡∏•‡∏≤‡πÑ‡∏õ‡∏Ñ‡∏•‡∏¥‡∏õ‡∏ñ‡∏±‡∏î‡πÑ‡∏õ\n",
    "\n",
    "# ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡∏Ñ‡∏•‡∏¥‡∏õ\n",
    "move_interval = 1  # 1 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡∏Ñ‡∏•‡∏¥‡∏õ\n",
    "move_duration = 5  # 5 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡∏Ñ‡∏•‡∏¥‡∏õ\n",
    "skip_interval = 5  # 5 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ‡∏´‡∏•‡∏±‡∏á‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≤‡∏°‡πÇ‡∏Ü‡∏©‡∏ì‡∏≤\n",
    "next_interval = 5  # 5 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ‡∏´‡∏•‡∏±‡∏á‡∏à‡∏≤‡∏Å‡πÑ‡∏õ‡∏Ñ‡∏•‡∏¥‡∏õ‡∏ñ‡∏±‡∏î‡πÑ‡∏õ\n",
    "\n",
    "while True:\n",
    "    success, img = cap.read()\n",
    "    hands, img = detector.findHands(img)\n",
    "\n",
    "    if hands:\n",
    "        for hand in hands:\n",
    "            fingers = detector.fingersUp(hand)  # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ô‡∏¥‡πâ‡∏ß‡∏ó‡∏µ‡πà‡∏¢‡∏Å\n",
    "\n",
    "            if hand[\"type\"] == \"Right\" and len(hand[\"lmList\"]) >= 9:  # ‡∏°‡∏∑‡∏≠‡∏Ç‡∏ß‡∏≤ -> ‡∏Ñ‡∏ß‡∏ö‡∏Ñ‡∏∏‡∏°‡πÄ‡∏™‡∏µ‡∏¢‡∏á\n",
    "                if fingers == [1, 1, 1, 1, 1]:  # ‡∏Å‡∏≤‡∏á‡∏°‡∏∑‡∏≠ 5 ‡∏ô‡∏¥‡πâ‡∏ß -> ‡∏´‡∏¢‡∏∏‡∏î‡∏ó‡∏µ‡πà‡∏£‡∏∞‡∏î‡∏±‡∏ö‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÄ‡∏î‡∏¥‡∏°\n",
    "                    adjusting_volume = False  \n",
    "\n",
    "                elif fingers == [1, 1, 0, 0, 0]:  # ‡∏ä‡∏π‡πÅ‡∏Ñ‡πà‡πÇ‡∏õ‡πâ‡∏á‡∏Å‡∏±‡∏ö‡∏ä‡∏µ‡πâ -> ‡∏õ‡∏£‡∏±‡∏ö‡πÄ‡∏™‡∏µ‡∏¢‡∏á\n",
    "                    adjusting_volume = True\n",
    "                    thumb_tip = hand[\"lmList\"][4]\n",
    "                    index_tip = hand[\"lmList\"][8]\n",
    "                    \n",
    "                    # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏£‡∏∞‡∏¢‡∏∞‡∏´‡πà‡∏≤‡∏á‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏ô‡∏¥‡πâ‡∏ß‡πÇ‡∏õ‡πâ‡∏á‡πÅ‡∏•‡∏∞‡∏ô‡∏¥‡πâ‡∏ß‡∏ä‡∏µ‡πâ\n",
    "                    distance_x = abs(thumb_tip[0] - index_tip[0])\n",
    "                    distance_y = abs(thumb_tip[1] - index_tip[1])\n",
    "                    distance = math.hypot(distance_x, distance_y)\n",
    "                    distance = max(min_distance, min(distance, max_distance))\n",
    "\n",
    "                    volume_scalar = (distance - min_distance) / (max_distance - min_distance)\n",
    "\n",
    "                    # ‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏ô‡∏∏‡πà‡∏°‡∏ô‡∏ß‡∏•‡∏Ç‡∏∂‡πâ‡∏ô\n",
    "                    smooth_factor = 0.2  \n",
    "                    last_volume = (1 - smooth_factor) * last_volume + smooth_factor * volume_scalar\n",
    "\n",
    "                    # ‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏ñ‡πâ‡∏≤‡∏ï‡πà‡∏≤‡∏á‡∏Å‡∏±‡∏ô‡∏ô‡πâ‡∏≠‡∏¢‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ\n",
    "                    if abs(volume.GetMasterVolumeLevelScalar() - last_volume) > 0.02:\n",
    "                        volume.SetMasterVolumeLevelScalar(last_volume, None)\n",
    "\n",
    "                    # ‡∏ß‡∏≤‡∏î‡πÄ‡∏™‡πâ‡∏ô‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏ô‡∏¥‡πâ‡∏ß‡πÇ‡∏õ‡πâ‡∏á‡∏Å‡∏±‡∏ö‡∏ä‡∏µ‡πâ\n",
    "                    cv2.line(img, (thumb_tip[0], thumb_tip[1]), (index_tip[0], index_tip[1]), (0, 255, 0), 3)\n",
    "\n",
    "                # ‡πÅ‡∏™‡∏î‡∏á‡∏£‡∏∞‡∏î‡∏±‡∏ö‡πÄ‡∏™‡∏µ‡∏¢‡∏á\n",
    "                volume_percent = int(last_volume * 100)\n",
    "                cv2.putText(img, f'Volume: {volume_percent}%', (50, 50),\n",
    "                            cv2.FONT_HERSHEY_COMPLEX, 1, (255, 0, 0), 2)\n",
    "\n",
    "                # ‡πÅ‡∏™‡∏î‡∏á‡πÅ‡∏ñ‡∏ö‡∏£‡∏∞‡∏î‡∏±‡∏ö‡πÄ‡∏™‡∏µ‡∏¢‡∏á\n",
    "                bar_height = int((1 - last_volume) * 300)\n",
    "                bar_color = (0, 255, 0) if last_volume > 0.5 else (0, 0, 255)  # ‡∏™‡∏µ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ß = ‡∏î‡∏±‡∏á, ‡πÅ‡∏î‡∏á = ‡πÄ‡∏ö‡∏≤\n",
    "                cv2.rectangle(img, (50, 100), (100, 400), (255, 0, 0), 3)  \n",
    "                cv2.rectangle(img, (50, 100 + bar_height), (100, 400), bar_color, -1)\n",
    "\n",
    "                # ‡πÅ‡∏™‡∏î‡∏á‡πÑ‡∏≠‡∏Ñ‡∏≠‡∏ô‡πÄ‡∏™‡∏µ‡∏¢‡∏á\n",
    "                cv2.putText(img, \"üîä\" if last_volume > 0.5 else \"üîà\", (120, 380), \n",
    "                            cv2.FONT_HERSHEY_COMPLEX, 1, bar_color, 2)\n",
    "\n",
    "            elif hand[\"type\"] == \"Left\" and len(hand[\"lmList\"]) >= 9:  # ‡∏°‡∏∑‡∏≠‡∏ã‡πâ‡∏≤‡∏¢ -> ‡∏Ñ‡∏ß‡∏ö‡∏Ñ‡∏∏‡∏°‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠\n",
    "                current_time = time.time()\n",
    "\n",
    "                if current_time - last_time > 1:  # ‡πÄ‡∏ä‡πá‡∏Ñ‡πÄ‡∏ß‡∏•‡∏≤‡∏´‡πà‡∏≤‡∏á‡∏Å‡∏±‡∏ô 1 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ\n",
    "                    if fingers == [0, 1, 0, 0, 0]:  # ‡∏ä‡∏µ‡πâ‡∏ô‡∏¥‡πâ‡∏ß‡∏°‡∏∑‡∏≠‡∏ã‡πâ‡∏≤‡∏¢‡πÑ‡∏õ‡∏ó‡∏≤‡∏á‡∏Ç‡∏ß‡∏≤ (‡πÄ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡∏Ñ‡∏•‡∏¥‡∏õ‡πÑ‡∏õ‡∏Ç‡πâ‡∏≤‡∏á‡∏´‡∏ô‡πâ‡∏≤ 5 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ)\n",
    "                        if current_time - last_move_time > move_interval:\n",
    "                            pyautogui.press('right')  # ‡πÄ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡∏Ñ‡∏•‡∏¥‡∏õ‡πÑ‡∏õ‡∏Ç‡πâ‡∏≤‡∏á‡∏´‡∏ô‡πâ‡∏≤ 5 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ\n",
    "                            last_move_time = current_time  # ‡∏£‡∏µ‡πÄ‡∏ã‡πá‡∏ï‡πÄ‡∏ß‡∏•‡∏≤‡∏Å‡∏≤‡∏£‡πÄ‡∏•‡∏∑‡πà‡∏≠‡∏ô\n",
    "\n",
    "                    elif fingers == [0, 1, 1, 0, 0]:  # ‡∏ä‡∏µ‡πâ 2 ‡∏ô‡∏¥‡πâ‡∏ß (‡∏ô‡∏¥‡πâ‡∏ß‡∏ä‡∏µ‡πâ, ‡∏ô‡∏¥‡πâ‡∏ß‡∏Å‡∏•‡∏≤‡∏á) (‡∏¢‡πâ‡∏≠‡∏ô‡∏Ñ‡∏•‡∏¥‡∏õ 5 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ)\n",
    "                        if current_time - last_move_time > move_interval:\n",
    "                            pyautogui.press('left')  # ‡πÄ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡∏Ñ‡∏•‡∏¥‡∏õ‡∏¢‡πâ‡∏≠‡∏ô‡∏Å‡∏•‡∏±‡∏ö 5 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ\n",
    "                            last_move_time = current_time  # ‡∏£‡∏µ‡πÄ‡∏ã‡πá‡∏ï‡πÄ‡∏ß‡∏•‡∏≤‡∏Å‡∏≤‡∏£‡πÄ‡∏•‡∏∑‡πà‡∏≠‡∏ô\n",
    "\n",
    "\n",
    "                    # ‡πÑ‡∏õ‡∏Ñ‡∏•‡∏¥‡∏õ‡∏ñ‡∏±‡∏î‡πÑ‡∏õ\n",
    "                    elif fingers == [0, 1, 1, 1, 1]:  # ‡∏ä‡∏µ‡πâ 4 ‡∏ô‡∏¥‡πâ‡∏ß (‡∏ä‡∏µ‡πâ‡∏ô‡∏¥‡πâ‡∏ß, ‡∏ô‡∏¥‡πâ‡∏ß‡∏Å‡∏•‡∏≤‡∏á, ‡∏ô‡∏¥‡πâ‡∏ß‡∏ô‡∏≤‡∏á, ‡∏ô‡∏¥‡πâ‡∏ß‡∏Å‡πâ‡∏≠‡∏¢)\n",
    "                        if current_time - last_next_time > next_interval:  # 5 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ\n",
    "                            pyautogui.hotkey('shift', 'n')  # ‡πÉ‡∏ä‡πâ shift + n ‡πÑ‡∏õ‡∏Ñ‡∏•‡∏¥‡∏õ‡∏ñ‡∏±‡∏î‡πÑ‡∏õ\n",
    "                            last_next_time = current_time  # ‡∏£‡∏µ‡πÄ‡∏ã‡πá‡∏ï‡πÄ‡∏ß‡∏•‡∏≤‡∏Å‡∏≤‡∏£‡πÑ‡∏õ‡∏Ñ‡∏•‡∏¥‡∏õ‡∏ñ‡∏±‡∏î‡πÑ‡∏õ\n",
    "\n",
    "\n",
    "                    elif fingers == [0, 0, 0, 0, 1]:  # ‡∏Å‡∏≥‡∏°‡∏∑‡∏≠ = ‡∏´‡∏¢‡∏∏‡∏î‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠\n",
    "                        pyautogui.press('space')  \n",
    "                        last_time = current_time  # ‡∏£‡∏µ‡πÄ‡∏ã‡πá‡∏ï‡πÄ‡∏ß‡∏•‡∏≤\n",
    "\n",
    "                    elif fingers == [1, 1, 1, 1, 1]:  # ‡πÅ‡∏ö‡∏°‡∏∑‡∏≠ 5 ‡∏ô‡∏¥‡πâ‡∏ß = ‡πÄ‡∏•‡πà‡∏ô‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠‡∏ï‡πà‡∏≠\n",
    "                        pyautogui.press('space')  \n",
    "                        last_time = current_time  # ‡∏£‡∏µ‡πÄ‡∏ã‡πá‡∏ï‡πÄ‡∏ß‡∏•‡∏≤\n",
    "\n",
    "    img = cv2.resize(img, (960, 720))\n",
    "    cv2.imshow(\"image\", img)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b79a9a49-2f1e-4319-ad4a-58d7deab58de",
   "metadata": {},
   "outputs": [],
   "source": [
    " import cv2\n",
    "from cvzone.HandTrackingModule import HandDetector\n",
    "import math\n",
    "from ctypes import cast, POINTER\n",
    "from comtypes import CLSCTX_ALL\n",
    "from pycaw.pycaw import AudioUtilities, IAudioEndpointVolume\n",
    "import pyautogui  # ‡πÉ‡∏ä‡πâ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ñ‡∏ß‡∏ö‡∏Ñ‡∏∏‡∏°‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠\n",
    "import time\n",
    "\n",
    "# ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏Å‡∏•‡πâ‡∏≠‡∏á\n",
    "cap = cv2.VideoCapture(0)\n",
    "detector = HandDetector(detectionCon=0.8)  # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö\n",
    "\n",
    "# ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏£‡∏∞‡∏ö‡∏ö‡πÄ‡∏™‡∏µ‡∏¢‡∏á\n",
    "devices = AudioUtilities.GetSpeakers()\n",
    "interface = devices.Activate(IAudioEndpointVolume._iid_, CLSCTX_ALL, None)\n",
    "volume = cast(interface, POINTER(IAudioEndpointVolume))\n",
    "\n",
    "# ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏Ñ‡πà‡∏≤‡∏ï‡πà‡∏≥‡∏™‡∏∏‡∏î-‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î‡∏Ç‡∏≠‡∏á‡∏£‡∏∞‡∏¢‡∏∞‡∏°‡∏∑‡∏≠\n",
    "min_distance = 20\n",
    "max_distance = 180\n",
    "adjusting_volume = False  # ‡πÄ‡∏ä‡πá‡∏Ñ‡∏ß‡πà‡∏≤‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏õ‡∏£‡∏±‡∏ö‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏≠‡∏¢‡∏π‡πà‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà\n",
    "last_volume = volume.GetMasterVolumeLevelScalar()  # ‡πÄ‡∏Å‡πá‡∏ö‡∏£‡∏∞‡∏î‡∏±‡∏ö‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î\n",
    "\n",
    "# ‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£‡πÉ‡∏´‡∏°‡πà‡πÄ‡∏ä‡πá‡∏Ñ‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏Å‡∏≤‡∏£‡∏Å‡∏î\n",
    "last_action = None\n",
    "last_time = time.time()  # ‡πÉ‡∏ä‡πâ‡∏à‡∏±‡∏ö‡πÄ‡∏ß‡∏•‡∏≤‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô‡∏Å‡∏≤‡∏£‡∏Å‡∏î‡∏ã‡πâ‡∏≥\n",
    "last_move_time = time.time()  # ‡∏à‡∏±‡∏ö‡πÄ‡∏ß‡∏•‡∏≤‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡∏Ñ‡∏•‡∏¥‡∏õ\n",
    "last_skip_time = time.time()  # ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏à‡∏±‡∏ö‡πÄ‡∏ß‡∏•‡∏≤‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏Ç‡πâ‡∏≤‡∏°‡πÇ‡∏Ü‡∏©‡∏ì‡∏≤\n",
    "last_next_time = time.time()  # ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏à‡∏±‡∏ö‡πÄ‡∏ß‡∏•‡∏≤‡πÑ‡∏õ‡∏Ñ‡∏•‡∏¥‡∏õ‡∏ñ‡∏±‡∏î‡πÑ‡∏õ\n",
    "\n",
    "# ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡∏Ñ‡∏•‡∏¥‡∏õ\n",
    "move_interval = 1  # 1 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡∏Ñ‡∏•‡∏¥‡∏õ\n",
    "move_duration = 5  # 5 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡∏Ñ‡∏•‡∏¥‡∏õ\n",
    "skip_interval = 5  # 5 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ‡∏´‡∏•‡∏±‡∏á‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≤‡∏°‡πÇ‡∏Ü‡∏©‡∏ì‡∏≤\n",
    "next_interval = 5  # 5 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ‡∏´‡∏•‡∏±‡∏á‡∏à‡∏≤‡∏Å‡πÑ‡∏õ‡∏Ñ‡∏•‡∏¥‡∏õ‡∏ñ‡∏±‡∏î‡πÑ‡∏õ\n",
    "\n",
    "while True:\n",
    "    success, img = cap.read()\n",
    "    hands, img = detector.findHands(img)\n",
    "\n",
    "    if hands:\n",
    "        for hand in hands:\n",
    "            fingers = detector.fingersUp(hand)  # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ô‡∏¥‡πâ‡∏ß‡∏ó‡∏µ‡πà‡∏¢‡∏Å\n",
    "\n",
    "            if hand[\"type\"] == \"Right\" and len(hand[\"lmList\"]) >= 9:  # ‡∏°‡∏∑‡∏≠‡∏Ç‡∏ß‡∏≤ -> ‡∏Ñ‡∏ß‡∏ö‡∏Ñ‡∏∏‡∏°‡πÄ‡∏™‡∏µ‡∏¢‡∏á\n",
    "                if fingers == [1, 1, 1, 1, 1]:  # ‡∏Å‡∏≤‡∏á‡∏°‡∏∑‡∏≠ 5 ‡∏ô‡∏¥‡πâ‡∏ß -> ‡∏´‡∏¢‡∏∏‡∏î‡∏ó‡∏µ‡πà‡∏£‡∏∞‡∏î‡∏±‡∏ö‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÄ‡∏î‡∏¥‡∏°\n",
    "                    adjusting_volume = False  \n",
    "\n",
    "                elif fingers == [1, 1, 0, 0, 0]:  # ‡∏ä‡∏π‡πÅ‡∏Ñ‡πà‡πÇ‡∏õ‡πâ‡∏á‡∏Å‡∏±‡∏ö‡∏ä‡∏µ‡πâ -> ‡∏õ‡∏£‡∏±‡∏ö‡πÄ‡∏™‡∏µ‡∏¢‡∏á\n",
    "                    adjusting_volume = True\n",
    "                    thumb_tip = hand[\"lmList\"][4]\n",
    "                    index_tip = hand[\"lmList\"][8]\n",
    "                    \n",
    "                    # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏£‡∏∞‡∏¢‡∏∞‡∏´‡πà‡∏≤‡∏á‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏ô‡∏¥‡πâ‡∏ß‡πÇ‡∏õ‡πâ‡∏á‡πÅ‡∏•‡∏∞‡∏ô‡∏¥‡πâ‡∏ß‡∏ä‡∏µ‡πâ\n",
    "                    distance_x = abs(thumb_tip[0] - index_tip[0])\n",
    "                    distance_y = abs(thumb_tip[1] - index_tip[1])\n",
    "                    distance = math.hypot(distance_x, distance_y)\n",
    "                    distance = max(min_distance, min(distance, max_distance))\n",
    "\n",
    "                    volume_scalar = (distance - min_distance) / (max_distance - min_distance)\n",
    "\n",
    "                    # ‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏ô‡∏∏‡πà‡∏°‡∏ô‡∏ß‡∏•‡∏Ç‡∏∂‡πâ‡∏ô\n",
    "                    smooth_factor = 0.2  \n",
    "                    last_volume = (1 - smooth_factor) * last_volume + smooth_factor * volume_scalar\n",
    "\n",
    "                    # ‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏ñ‡πâ‡∏≤‡∏ï‡πà‡∏≤‡∏á‡∏Å‡∏±‡∏ô‡∏ô‡πâ‡∏≠‡∏¢‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ\n",
    "                    if abs(volume.GetMasterVolumeLevelScalar() - last_volume) > 0.02:\n",
    "                        volume.SetMasterVolumeLevelScalar(last_volume, None)\n",
    "\n",
    "                    # ‡∏ß‡∏≤‡∏î‡πÄ‡∏™‡πâ‡∏ô‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏ô‡∏¥‡πâ‡∏ß‡πÇ‡∏õ‡πâ‡∏á‡∏Å‡∏±‡∏ö‡∏ä‡∏µ‡πâ\n",
    "                    cv2.line(img, (thumb_tip[0], thumb_tip[1]), (index_tip[0], index_tip[1]), (0, 255, 0), 3)\n",
    "\n",
    "                # ‡πÅ‡∏™‡∏î‡∏á‡∏£‡∏∞‡∏î‡∏±‡∏ö‡πÄ‡∏™‡∏µ‡∏¢‡∏á\n",
    "                volume_percent = int(last_volume * 100)\n",
    "                cv2.putText(img, f'Volume: {volume_percent}%', (50, 50),\n",
    "                            cv2.FONT_HERSHEY_COMPLEX, 1, (255, 0, 0), 2)\n",
    "\n",
    "                # ‡πÅ‡∏™‡∏î‡∏á‡πÅ‡∏ñ‡∏ö‡∏£‡∏∞‡∏î‡∏±‡∏ö‡πÄ‡∏™‡∏µ‡∏¢‡∏á\n",
    "                bar_height = int((1 - last_volume) * 300)\n",
    "                bar_color = (0, 255, 0) if last_volume > 0.5 else (0, 0, 255)  # ‡∏™‡∏µ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ß = ‡∏î‡∏±‡∏á, ‡πÅ‡∏î‡∏á = ‡πÄ‡∏ö‡∏≤\n",
    "                cv2.rectangle(img, (50, 100), (100, 400), (255, 0, 0), 3)  \n",
    "                cv2.rectangle(img, (50, 100 + bar_height), (100, 400), bar_color, -1)\n",
    "\n",
    "                # ‡πÅ‡∏™‡∏î‡∏á‡πÑ‡∏≠‡∏Ñ‡∏≠‡∏ô‡πÄ‡∏™‡∏µ‡∏¢‡∏á\n",
    "                cv2.putText(img, \"üîä\" if last_volume > 0.5 else \"üîà\", (120, 380), \n",
    "                            cv2.FONT_HERSHEY_COMPLEX, 1, bar_color, 2)\n",
    "\n",
    "            elif hand[\"type\"] == \"Left\" and len(hand[\"lmList\"]) >= 9:  # ‡∏°‡∏∑‡∏≠‡∏ã‡πâ‡∏≤‡∏¢ -> ‡∏Ñ‡∏ß‡∏ö‡∏Ñ‡∏∏‡∏°‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠\n",
    "                current_time = time.time()\n",
    "\n",
    "                if current_time - last_time > 1:  # ‡πÄ‡∏ä‡πá‡∏Ñ‡πÄ‡∏ß‡∏•‡∏≤‡∏´‡πà‡∏≤‡∏á‡∏Å‡∏±‡∏ô 1 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ\n",
    "                    if fingers == [0, 1, 0, 0, 0]:  # ‡∏ä‡∏µ‡πâ‡∏ô‡∏¥‡πâ‡∏ß‡∏°‡∏∑‡∏≠‡∏ã‡πâ‡∏≤‡∏¢‡πÑ‡∏õ‡∏ó‡∏≤‡∏á‡∏Ç‡∏ß‡∏≤ (‡πÄ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡∏Ñ‡∏•‡∏¥‡∏õ‡πÑ‡∏õ‡∏Ç‡πâ‡∏≤‡∏á‡∏´‡∏ô‡πâ‡∏≤ 5 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ)\n",
    "                        if current_time - last_move_time > move_interval:\n",
    "                            pyautogui.press('right')  # ‡πÄ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡∏Ñ‡∏•‡∏¥‡∏õ‡πÑ‡∏õ‡∏Ç‡πâ‡∏≤‡∏á‡∏´‡∏ô‡πâ‡∏≤ 5 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ\n",
    "                            last_move_time = current_time  # ‡∏£‡∏µ‡πÄ‡∏ã‡πá‡∏ï‡πÄ‡∏ß‡∏•‡∏≤‡∏Å‡∏≤‡∏£‡πÄ‡∏•‡∏∑‡πà‡∏≠‡∏ô\n",
    "\n",
    "                    elif fingers == [0, 1, 1, 0, 0]:  # ‡∏ä‡∏µ‡πâ 2 ‡∏ô‡∏¥‡πâ‡∏ß (‡∏ô‡∏¥‡πâ‡∏ß‡∏ä‡∏µ‡πâ, ‡∏ô‡∏¥‡πâ‡∏ß‡∏Å‡∏•‡∏≤‡∏á) (‡∏¢‡πâ‡∏≠‡∏ô‡∏Ñ‡∏•‡∏¥‡∏õ 5 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ)\n",
    "                        if current_time - last_move_time > move_interval:\n",
    "                            pyautogui.press('left')  # ‡πÄ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡∏Ñ‡∏•‡∏¥‡∏õ‡∏¢‡πâ‡∏≠‡∏ô‡∏Å‡∏•‡∏±‡∏ö 5 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ\n",
    "                            last_move_time = current_time  # ‡∏£‡∏µ‡πÄ‡∏ã‡πá‡∏ï‡πÄ‡∏ß‡∏•‡∏≤‡∏Å‡∏≤‡∏£‡πÄ‡∏•‡∏∑‡πà‡∏≠‡∏ô\n",
    "\n",
    "\n",
    "                    # ‡πÑ‡∏õ‡∏Ñ‡∏•‡∏¥‡∏õ‡∏ñ‡∏±‡∏î‡πÑ‡∏õ\n",
    "                    elif fingers == [0, 1, 1, 1, 1]:  # ‡∏ä‡∏µ‡πâ 4 ‡∏ô‡∏¥‡πâ‡∏ß (‡∏ä‡∏µ‡πâ‡∏ô‡∏¥‡πâ‡∏ß, ‡∏ô‡∏¥‡πâ‡∏ß‡∏Å‡∏•‡∏≤‡∏á, ‡∏ô‡∏¥‡πâ‡∏ß‡∏ô‡∏≤‡∏á, ‡∏ô‡∏¥‡πâ‡∏ß‡∏Å‡πâ‡∏≠‡∏¢)\n",
    "                        if current_time - last_next_time > next_interval:  # 5 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ\n",
    "                            pyautogui.hotkey('shift', 'n')  # ‡πÉ‡∏ä‡πâ shift + n ‡πÑ‡∏õ‡∏Ñ‡∏•‡∏¥‡∏õ‡∏ñ‡∏±‡∏î‡πÑ‡∏õ\n",
    "                            last_next_time = current_time  # ‡∏£‡∏µ‡πÄ‡∏ã‡πá‡∏ï‡πÄ‡∏ß‡∏•‡∏≤‡∏Å‡∏≤‡∏£‡πÑ‡∏õ‡∏Ñ‡∏•‡∏¥‡∏õ‡∏ñ‡∏±‡∏î‡πÑ‡∏õ\n",
    "\n",
    "\n",
    "                    elif fingers == [0, 0, 0, 0, 1]:  # ‡∏Å‡∏≥‡∏°‡∏∑‡∏≠ = ‡∏´‡∏¢‡∏∏‡∏î‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠\n",
    "                        pyautogui.press('space')  \n",
    "                        last_time = current_time  # ‡∏£‡∏µ‡πÄ‡∏ã‡πá‡∏ï‡πÄ‡∏ß‡∏•‡∏≤\n",
    "\n",
    "                    elif fingers == [1, 1, 1, 1, 1]:  # ‡πÅ‡∏ö‡∏°‡∏∑‡∏≠ 5 ‡∏ô‡∏¥‡πâ‡∏ß = ‡πÄ‡∏•‡πà‡∏ô‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠‡∏ï‡πà‡∏≠\n",
    "                        pyautogui.press('space')  \n",
    "                        last_time = current_time  # ‡∏£‡∏µ‡πÄ‡∏ã‡πá‡∏ï‡πÄ‡∏ß‡∏•‡∏≤\n",
    "\n",
    "    img = cv2.resize(img, (960, 720))\n",
    "    cv2.imshow(\"image\", img)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b49dc404-35af-4aca-85a9-cc92e5c4c460",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from cvzone.HandTrackingModule import HandDetector\n",
    "import math\n",
    "from ctypes import cast, POINTER\n",
    "from comtypes import CLSCTX_ALL\n",
    "from pycaw.pycaw import AudioUtilities, IAudioEndpointVolume\n",
    "import pyautogui  # ‡πÉ‡∏ä‡πâ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ñ‡∏ß‡∏ö‡∏Ñ‡∏∏‡∏°‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠\n",
    "import time\n",
    "\n",
    "# =======================\n",
    "# ‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà 1: ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏Å‡∏•‡πâ‡∏≠‡∏á\n",
    "# =======================\n",
    "cap = cv2.VideoCapture(0)\n",
    "detector = HandDetector(detectionCon=0.9)  # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö\n",
    "\n",
    "# =======================\n",
    "# ‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà 2: ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏£‡∏∞‡∏ö‡∏ö‡πÄ‡∏™‡∏µ‡∏¢‡∏á\n",
    "# =======================\n",
    "devices = AudioUtilities.GetSpeakers()\n",
    "interface = devices.Activate(IAudioEndpointVolume._iid_, CLSCTX_ALL, None)\n",
    "volume = cast(interface, POINTER(IAudioEndpointVolume))\n",
    "\n",
    "# ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏Ñ‡πà‡∏≤‡∏ï‡πà‡∏≥‡∏™‡∏∏‡∏î-‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î‡∏Ç‡∏≠‡∏á‡∏£‡∏∞‡∏¢‡∏∞‡∏°‡∏∑‡∏≠\n",
    "min_distance = 20\n",
    "max_distance = 180\n",
    "adjusting_volume = False  # ‡πÄ‡∏ä‡πá‡∏Ñ‡∏ß‡πà‡∏≤‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏õ‡∏£‡∏±‡∏ö‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏≠‡∏¢‡∏π‡πà‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà\n",
    "last_volume = volume.GetMasterVolumeLevelScalar()  # ‡πÄ‡∏Å‡πá‡∏ö‡∏£‡∏∞‡∏î‡∏±‡∏ö‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î\n",
    "\n",
    "# =======================\n",
    "# ‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà 3: ‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡πÄ‡∏ß‡∏•‡∏≤‡∏ï‡πà‡∏≤‡∏á‡πÜ\n",
    "# =======================\n",
    "last_action = None\n",
    "last_time = time.time()  # ‡πÉ‡∏ä‡πâ‡∏à‡∏±‡∏ö‡πÄ‡∏ß‡∏•‡∏≤‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô‡∏Å‡∏≤‡∏£‡∏Å‡∏î‡∏ã‡πâ‡∏≥\n",
    "last_move_time = time.time()  # ‡∏à‡∏±‡∏ö‡πÄ‡∏ß‡∏•‡∏≤‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡∏Ñ‡∏•‡∏¥‡∏õ\n",
    "last_next_time = time.time()  # ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏à‡∏±‡∏ö‡πÄ‡∏ß‡∏•‡∏≤‡πÑ‡∏õ‡∏Ñ‡∏•‡∏¥‡∏õ‡∏ñ‡∏±‡∏î‡πÑ‡∏õ\n",
    "\n",
    "# ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡∏Ñ‡∏•‡∏¥‡∏õ\n",
    "move_interval = 1  # 1 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡∏Ñ‡∏•‡∏¥‡∏õ\n",
    "next_interval = 5  # 5 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ‡∏´‡∏•‡∏±‡∏á‡∏à‡∏≤‡∏Å‡πÑ‡∏õ‡∏Ñ‡∏•‡∏¥‡∏õ‡∏ñ‡∏±‡∏î‡πÑ‡∏õ\n",
    "\n",
    "# =======================\n",
    "# ‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà 4: ‡∏Å‡∏≤‡∏£‡∏≠‡πà‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡∏Å‡∏•‡πâ‡∏≠‡∏á\n",
    "# =======================\n",
    "while True:\n",
    "    success, img = cap.read()\n",
    "    hands, img = detector.findHands(img)\n",
    "\n",
    "    if hands:\n",
    "        for hand in hands:\n",
    "            fingers = detector.fingersUp(hand)  # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ô‡∏¥‡πâ‡∏ß‡∏ó‡∏µ‡πà‡∏¢‡∏Å\n",
    "\n",
    "            # =======================\n",
    "            # ‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà 5: ‡∏Å‡∏≤‡∏£‡∏Ñ‡∏ß‡∏ö‡∏Ñ‡∏∏‡∏°‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏î‡πâ‡∏ß‡∏¢‡∏°‡∏∑‡∏≠‡∏Ç‡∏ß‡∏≤\n",
    "            # =======================\n",
    "            if hand[\"type\"] == \"Right\" and len(hand[\"lmList\"]) >= 9:  # ‡∏°‡∏∑‡∏≠‡∏Ç‡∏ß‡∏≤ -> ‡∏Ñ‡∏ß‡∏ö‡∏Ñ‡∏∏‡∏°‡πÄ‡∏™‡∏µ‡∏¢‡∏á\n",
    "                if fingers == [1, 1, 1, 1, 1]:  # ‡∏Å‡∏≤‡∏á‡∏°‡∏∑‡∏≠ 5 ‡∏ô‡∏¥‡πâ‡∏ß -> ‡∏´‡∏¢‡∏∏‡∏î‡∏ó‡∏µ‡πà‡∏£‡∏∞‡∏î‡∏±‡∏ö‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÄ‡∏î‡∏¥‡∏°\n",
    "                    adjusting_volume = False  \n",
    "\n",
    "                elif fingers == [1, 1, 0, 0, 0]:  # ‡∏ä‡∏π‡πÅ‡∏Ñ‡πà‡πÇ‡∏õ‡πâ‡∏á‡∏Å‡∏±‡∏ö‡∏ä‡∏µ‡πâ -> ‡∏õ‡∏£‡∏±‡∏ö‡πÄ‡∏™‡∏µ‡∏¢‡∏á\n",
    "                    adjusting_volume = True\n",
    "                    thumb_tip = hand[\"lmList\"][4]\n",
    "                    index_tip = hand[\"lmList\"][8]\n",
    "                    \n",
    "                    # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏£‡∏∞‡∏¢‡∏∞‡∏´‡πà‡∏≤‡∏á‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏ô‡∏¥‡πâ‡∏ß‡πÇ‡∏õ‡πâ‡∏á‡πÅ‡∏•‡∏∞‡∏ô‡∏¥‡πâ‡∏ß‡∏ä‡∏µ‡πâ\n",
    "                    distance_x = abs(thumb_tip[0] - index_tip[0])\n",
    "                    distance_y = abs(thumb_tip[1] - index_tip[1])\n",
    "                    distance = math.hypot(distance_x, distance_y)\n",
    "                    distance = max(min_distance, min(distance, max_distance))\n",
    "\n",
    "                    volume_scalar = (distance - min_distance) / (max_distance - min_distance)\n",
    "\n",
    "                    # ‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏ô‡∏∏‡πà‡∏°‡∏ô‡∏ß‡∏•‡∏Ç‡∏∂‡πâ‡∏ô\n",
    "                    smooth_factor = 0.2  \n",
    "                    last_volume = (1 - smooth_factor) * last_volume + smooth_factor * volume_scalar\n",
    "\n",
    "                    # ‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏ñ‡πâ‡∏≤‡∏ï‡πà‡∏≤‡∏á‡∏Å‡∏±‡∏ô‡∏ô‡πâ‡∏≠‡∏¢‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ\n",
    "                    if abs(volume.GetMasterVolumeLevelScalar() - last_volume) > 0.02:\n",
    "                        volume.SetMasterVolumeLevelScalar(last_volume, None)\n",
    "\n",
    "                    # ‡∏ß‡∏≤‡∏î‡πÄ‡∏™‡πâ‡∏ô‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏ô‡∏¥‡πâ‡∏ß‡πÇ‡∏õ‡πâ‡∏á‡∏Å‡∏±‡∏ö‡∏ä‡∏µ‡πâ\n",
    "                    cv2.line(img, (thumb_tip[0], thumb_tip[1]), (index_tip[0], index_tip[1]), (0, 255, 0), 3)\n",
    "\n",
    "                # ‡πÅ‡∏™‡∏î‡∏á‡∏£‡∏∞‡∏î‡∏±‡∏ö‡πÄ‡∏™‡∏µ‡∏¢‡∏á\n",
    "                volume_percent = int(last_volume * 100)\n",
    "                cv2.putText(img, f'Volume: {volume_percent}%', (50, 50),\n",
    "                            cv2.FONT_HERSHEY_COMPLEX, 1, (255, 0, 0), 2)\n",
    "\n",
    "                # ‡πÅ‡∏™‡∏î‡∏á‡πÅ‡∏ñ‡∏ö‡∏£‡∏∞‡∏î‡∏±‡∏ö‡πÄ‡∏™‡∏µ‡∏¢‡∏á\n",
    "                bar_height = int((1 - last_volume) * 300)\n",
    "                bar_color = (0, 255, 0) if last_volume > 0.5 else (0, 0, 255)  # ‡∏™‡∏µ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ß = ‡∏î‡∏±‡∏á, ‡πÅ‡∏î‡∏á = ‡πÄ‡∏ö‡∏≤\n",
    "                cv2.rectangle(img, (50, 100), (100, 400), (255, 0, 0), 3)  \n",
    "                cv2.rectangle(img, (50, 100 + bar_height), (100, 400), bar_color, -1)\n",
    "\n",
    "                # ‡πÅ‡∏™‡∏î‡∏á‡πÑ‡∏≠‡∏Ñ‡∏≠‡∏ô‡πÄ‡∏™‡∏µ‡∏¢‡∏á\n",
    "                cv2.putText(img, \"üîä\" if last_volume > 0.5 else \"üîà\", (120, 380), \n",
    "                            cv2.FONT_HERSHEY_COMPLEX, 1, bar_color, 2)\n",
    "\n",
    "            # =======================\n",
    "            # ‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà 6: ‡∏Å‡∏≤‡∏£‡∏Ñ‡∏ß‡∏ö‡∏Ñ‡∏∏‡∏°‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠‡∏î‡πâ‡∏ß‡∏¢‡∏°‡∏∑‡∏≠‡∏ã‡πâ‡∏≤‡∏¢\n",
    "            # =======================\n",
    "            elif hand[\"type\"] == \"Left\" and len(hand[\"lmList\"]) >= 9:  # ‡∏°‡∏∑‡∏≠‡∏ã‡πâ‡∏≤‡∏¢ -> ‡∏Ñ‡∏ß‡∏ö‡∏Ñ‡∏∏‡∏°‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠\n",
    "                current_time = time.time()\n",
    "\n",
    "                if current_time - last_time > 1:  # ‡πÄ‡∏ä‡πá‡∏Ñ‡πÄ‡∏ß‡∏•‡∏≤‡∏´‡πà‡∏≤‡∏á‡∏Å‡∏±‡∏ô 1 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ\n",
    "                    if fingers == [0, 1, 0, 0, 0]:  # ‡∏ä‡∏µ‡πâ‡∏ô‡∏¥‡πâ‡∏ß‡∏°‡∏∑‡∏≠‡∏ã‡πâ‡∏≤‡∏¢‡πÑ‡∏õ‡∏ó‡∏≤‡∏á‡∏Ç‡∏ß‡∏≤ (‡πÄ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡∏Ñ‡∏•‡∏¥‡∏õ‡πÑ‡∏õ‡∏Ç‡πâ‡∏≤‡∏á‡∏´‡∏ô‡πâ‡∏≤ 5 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ)\n",
    "                        if current_time - last_move_time > move_interval:\n",
    "                            pyautogui.press('right')  # ‡πÄ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡∏Ñ‡∏•‡∏¥‡∏õ‡πÑ‡∏õ‡∏Ç‡πâ‡∏≤‡∏á‡∏´‡∏ô‡πâ‡∏≤ 5 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ\n",
    "                            last_move_time = current_time  # ‡∏£‡∏µ‡πÄ‡∏ã‡πá‡∏ï‡πÄ‡∏ß‡∏•‡∏≤‡∏Å‡∏≤‡∏£‡πÄ‡∏•‡∏∑‡πà‡∏≠‡∏ô\n",
    "\n",
    "                    elif fingers == [0, 1, 1, 0, 0]:  # ‡∏ä‡∏µ‡πâ 2 ‡∏ô‡∏¥‡πâ‡∏ß (‡∏ô‡∏¥‡πâ‡∏ß‡∏ä‡∏µ‡πâ, ‡∏ô‡∏¥‡πâ‡∏ß‡∏Å‡∏•‡∏≤‡∏á) (‡∏¢‡πâ‡∏≠‡∏ô‡∏Ñ‡∏•‡∏¥‡∏õ 5 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ)\n",
    "                        if current_time - last_move_time > move_interval:\n",
    "                            pyautogui.press('left')  # ‡πÄ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡∏Ñ‡∏•‡∏¥‡∏õ‡∏¢‡πâ‡∏≠‡∏ô‡∏Å‡∏•‡∏±‡∏ö 5 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ\n",
    "                            last_move_time = current_time  # ‡∏£‡∏µ‡πÄ‡∏ã‡πá‡∏ï‡πÄ‡∏ß‡∏•‡∏≤‡∏Å‡∏≤‡∏£‡πÄ‡∏•‡∏∑‡πà‡∏≠‡∏ô\n",
    "\n",
    "                    # ‡πÑ‡∏õ‡∏Ñ‡∏•‡∏¥‡∏õ‡∏ñ‡∏±‡∏î‡πÑ‡∏õ\n",
    "                    elif fingers == [0, 1, 1, 1, 1]:  # ‡∏ä‡∏µ‡πâ 4 ‡∏ô‡∏¥‡πâ‡∏ß (‡∏ä‡∏µ‡πâ‡∏ô‡∏¥‡πâ‡∏ß, ‡∏ô‡∏¥‡πâ‡∏ß‡∏Å‡∏•‡∏≤‡∏á, ‡∏ô‡∏¥‡πâ‡∏ß‡∏ô‡∏≤‡∏á, ‡∏ô‡∏¥‡πâ‡∏ß‡∏Å‡πâ‡∏≠‡∏¢)\n",
    "                        if current_time - last_next_time > next_interval:  # 5 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ\n",
    "                            pyautogui.hotkey('shift', 'n')  # ‡πÉ‡∏ä‡πâ shift + n ‡πÑ‡∏õ‡∏Ñ‡∏•‡∏¥‡∏õ‡∏ñ‡∏±‡∏î‡πÑ‡∏õ\n",
    "                            last_next_time = current_time  # ‡∏£‡∏µ‡πÄ‡∏ã‡πá‡∏ï‡πÄ‡∏ß‡∏•‡∏≤‡∏Å‡∏≤‡∏£‡πÑ‡∏õ‡∏Ñ‡∏•‡∏¥‡∏õ‡∏ñ‡∏±‡∏î‡πÑ‡∏õ\n",
    "\n",
    "                    elif fingers == [1, 1, 1, 1, 1]:  # ‡πÅ‡∏ö‡∏°‡∏∑‡∏≠ 5 ‡∏ô‡∏¥‡πâ‡∏ß = ‡πÄ‡∏•‡πà‡∏ô‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠‡∏ï‡πà‡∏≠\n",
    "                        pyautogui.press('space')  \n",
    "                        last_time = current_time  # ‡∏£‡∏µ‡πÄ‡∏ã‡πá‡∏ï‡πÄ‡∏ß‡∏•‡∏≤\n",
    "\n",
    "    # =======================\n",
    "    # ‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà 7: ‡∏Å‡∏≤‡∏£‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏†‡∏≤‡∏û \n",
    "    # =======================\n",
    "    img = cv2.resize(img, (960, 720))\n",
    "    cv2.imshow(\"image\", img)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# =======================\n",
    "# ‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà 8: ‡∏õ‡∏¥‡∏î‡∏Å‡∏•‡πâ‡∏≠‡∏á‡πÅ‡∏•‡∏∞‡∏´‡∏ô‡πâ‡∏≤‡∏ï‡πà‡∏≤‡∏á\n",
    "# =======================\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d959eeb-1d45-4908-8766-81646ec2873a",
   "metadata": {},
   "source": [
    "# 1. Business Understanding\n",
    "Objective:\n",
    "Develop an application that allows users to control volume and video playback using hand gestures, such as adjusting the volume, skipping clips, or pausing/playing videos.\n",
    "\n",
    "Business Questions:\n",
    "- Do users need a convenient way to control volume without touching their devices or using voice commands?\n",
    "- Do users want an easy way to manage video playback using hand movements?\n",
    "  \n",
    "Goals:\n",
    "- Use hand motion detection to adjust the volume by measuring the distance between the thumb and index finger.\n",
    "- Utilize hand gestures to control video playback (pause, play, skip forward, rewind)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e1628d2c-01d3-44fa-a517-b9c97432f17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡∏õ‡∏£‡∏∞‡∏™‡∏á‡∏Ñ‡πå‡∏ó‡∏µ‡πà‡∏ï‡∏±‡πâ‡∏á‡πÑ‡∏ß‡πâ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏û‡∏±‡∏í‡∏ô‡∏≤‡πÅ‡∏≠‡∏õ\n",
    "import cv2\n",
    "from cvzone.HandTrackingModule import HandDetector\n",
    "import math\n",
    "from ctypes import cast, POINTER\n",
    "from comtypes import CLSCTX_ALL\n",
    "from pycaw.pycaw import AudioUtilities, IAudioEndpointVolume\n",
    "import pyautogui\n",
    "import time\n",
    "\n",
    "# ‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏Å‡∏•‡πâ‡∏≠‡∏á‡πÅ‡∏•‡∏∞‡∏ï‡∏±‡∏ß‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏°‡∏∑‡∏≠\n",
    "cap = cv2.VideoCapture(0)\n",
    "detector = HandDetector(detectionCon=0.8)  # ‡πÉ‡∏ä‡πâ‡∏ï‡∏±‡∏ß‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏°‡∏∑‡∏≠‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡∏™‡∏π‡∏á\n",
    "\n",
    "# ‡∏Å‡∏≤‡∏£‡∏Ñ‡∏ß‡∏ö‡∏Ñ‡∏∏‡∏°‡∏£‡∏∞‡∏î‡∏±‡∏ö‡πÄ‡∏™‡∏µ‡∏¢‡∏á\n",
    "devices = AudioUtilities.GetSpeakers()\n",
    "interface = devices.Activate(IAudioEndpointVolume._iid_, CLSCTX_ALL, None)\n",
    "volume = cast(interface, POINTER(IAudioEndpointVolume))  # ‡∏Ñ‡∏ß‡∏ö‡∏Ñ‡∏∏‡∏°‡∏£‡∏∞‡∏î‡∏±‡∏ö‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏à‡∏≤‡∏Å pycaw\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba96449c-d804-4653-87af-6e8ffc6c3865",
   "metadata": {},
   "source": [
    "# 2. Data Understanding\n",
    "Data Sources:\n",
    "- Camera Data: Captured using cv2.VideoCapture(0) to obtain images from the webcam.\n",
    "- Hand Movement Data: Processed using the HandDetector module from cvzone to detect and analyze hand gestures.\n",
    "- Volume Level Data: Managed using the pycaw library to control system volume.\n",
    "- Video Playback Control Data: Handled via pyautogui to simulate keyboard inputs for skipping, pausing, or playing videos.\n",
    "  \n",
    "Data Preparation:\n",
    "- The raw camera input will be processed to detect and recognize hand movements, enabling gesture-based control functionalities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d088abc8-07aa-40e9-9406-645a4ffdffd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡∏Å‡∏•‡πâ‡∏≠‡∏á‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏°‡∏∑‡∏≠\n",
    "cap = cv2.VideoCapture(0)  # ‡πÄ‡∏õ‡∏¥‡∏î‡∏Å‡∏•‡πâ‡∏≠‡∏á‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏à‡∏±‡∏ö‡∏†‡∏≤‡∏û\n",
    "detector = HandDetector(detectionCon=0.8)  # ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏°‡∏∑‡∏≠\n",
    "\n",
    "# ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡∏≤‡∏£‡∏Ñ‡∏ß‡∏ö‡∏Ñ‡∏∏‡∏°‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏à‡∏≤‡∏Å pycaw\n",
    "devices = AudioUtilities.GetSpeakers()\n",
    "interface = devices.Activate(IAudioEndpointVolume._iid_, CLSCTX_ALL, None)\n",
    "volume = cast(interface, POINTER(IAudioEndpointVolume))  # ‡∏Ñ‡∏ß‡∏ö‡∏Ñ‡∏∏‡∏°‡∏£‡∏∞‡∏î‡∏±‡∏ö‡πÄ‡∏™‡∏µ‡∏¢‡∏á\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbdc503e-970a-4d14-b415-4b9813099637",
   "metadata": {},
   "source": [
    "# 3. Data Preparation\n",
    "Steps for Data Preparation:\n",
    "- Use cv2.VideoCapture to capture data from the camera.\n",
    "- Use HandDetector to extract hand movement data, such as finger coordinates.\n",
    "- Calculate the distance between the thumb and index finger to control the volume level.\n",
    "- Utilize hand movement data to manage video playback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13ae594-7855-47d5-9ff4-e932c10f7499",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‡∏≠‡πà‡∏≤‡∏ô‡∏†‡∏≤‡∏û‡∏à‡∏≤‡∏Å‡∏Å‡∏•‡πâ‡∏≠‡∏á\n",
    "success, img = cap.read()  # ‡∏≠‡πà‡∏≤‡∏ô‡∏†‡∏≤‡∏û‡∏à‡∏≤‡∏Å‡∏Å‡∏•‡πâ‡∏≠‡∏á\n",
    "hands, img = detector.findHands(img)  # ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏°‡∏∑‡∏≠‡∏à‡∏≤‡∏Å‡∏†‡∏≤‡∏û\n",
    "\n",
    "# ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏°‡∏∑‡∏≠‡πÅ‡∏•‡∏∞‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ó‡πà‡∏≤‡∏ó‡∏≤‡∏á‡∏ô‡∏¥‡πâ‡∏ß‡∏°‡∏∑‡∏≠\n",
    "if hands:  # ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡∏°‡∏∑‡∏≠\n",
    "    for hand in hands:  # ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏°‡∏∑‡∏≠‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏Ç‡πâ‡∏≤‡∏á\n",
    "        fingers = detector.fingersUp(hand)  # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ô‡∏¥‡πâ‡∏ß‡∏ó‡∏µ‡πà‡∏¢‡∏Å\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9db74ce-4ae6-4443-a01d-4609d200efe0",
   "metadata": {},
   "source": [
    "# 4. Modeling\n",
    "Model Used:\n",
    "- No machine learning model is used; instead, hand detection and distance calculation are implemented.\n",
    "  \n",
    "- Volume Control: The volume level is adjusted based on the distance between the thumb and index finger.\n",
    "- Video Playback Control: Hand gestures are used to manage video playback (skip, pause, play)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1848bc5c-326e-4075-a153-450e87d0a0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏£‡∏∞‡∏¢‡∏∞‡∏´‡πà‡∏≤‡∏á‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏ô‡∏¥‡πâ‡∏ß‡πÇ‡∏õ‡πâ‡∏á‡πÅ‡∏•‡∏∞‡∏ô‡∏¥‡πâ‡∏ß‡∏ä‡∏µ‡πâ\n",
    "thumb_tip = hand[\"lmList\"][4]\n",
    "index_tip = hand[\"lmList\"][8]\n",
    "\n",
    "distance_x = abs(thumb_tip[0] - index_tip[0])\n",
    "distance_y = abs(thumb_tip[1] - index_tip[1])\n",
    "distance = math.hypot(distance_x, distance_y)  # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏£‡∏∞‡∏¢‡∏∞‡∏´‡πà‡∏≤‡∏á\n",
    "distance = max(min_distance, min(distance, max_distance))\n",
    "\n",
    "# ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏£‡∏∞‡∏î‡∏±‡∏ö‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏à‡∏≤‡∏Å‡∏£‡∏∞‡∏¢‡∏∞‡∏´‡πà‡∏≤‡∏á\n",
    "volume_scalar = (distance - min_distance) / (max_distance - min_distance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b82b322-9b9e-40fa-9010-6d532251fe45",
   "metadata": {},
   "outputs": [],
   "source": [
    " if current_time - last_time > 1:  # ‡πÄ‡∏ä‡πá‡∏Ñ‡πÄ‡∏ß‡∏•‡∏≤‡∏´‡πà‡∏≤‡∏á‡∏Å‡∏±‡∏ô 1 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ\n",
    "                    if fingers == [0, 1, 0, 0, 0]:  # ‡∏ä‡∏µ‡πâ‡∏ô‡∏¥‡πâ‡∏ß‡∏°‡∏∑‡∏≠‡∏ã‡πâ‡∏≤‡∏¢‡πÑ‡∏õ‡∏ó‡∏≤‡∏á‡∏Ç‡∏ß‡∏≤ (‡πÄ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡∏Ñ‡∏•‡∏¥‡∏õ‡πÑ‡∏õ‡∏Ç‡πâ‡∏≤‡∏á‡∏´‡∏ô‡πâ‡∏≤ 5 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ)\n",
    "                        if current_time - last_move_time > move_interval:\n",
    "                            pyautogui.press('right')  # ‡πÄ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡∏Ñ‡∏•‡∏¥‡∏õ‡πÑ‡∏õ‡∏Ç‡πâ‡∏≤‡∏á‡∏´‡∏ô‡πâ‡∏≤ 5 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ\n",
    "                            last_move_time = current_time  # ‡∏£‡∏µ‡πÄ‡∏ã‡πá‡∏ï‡πÄ‡∏ß‡∏•‡∏≤‡∏Å‡∏≤‡∏£‡πÄ‡∏•‡∏∑‡πà‡∏≠‡∏ô\n",
    "\n",
    "                    elif fingers == [0, 1, 1, 0, 0]:  # ‡∏ä‡∏µ‡πâ 2 ‡∏ô‡∏¥‡πâ‡∏ß (‡∏ô‡∏¥‡πâ‡∏ß‡∏ä‡∏µ‡πâ, ‡∏ô‡∏¥‡πâ‡∏ß‡∏Å‡∏•‡∏≤‡∏á) (‡∏¢‡πâ‡∏≠‡∏ô‡∏Ñ‡∏•‡∏¥‡∏õ 5 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ)\n",
    "                        if current_time - last_move_time > move_interval:\n",
    "                            pyautogui.press('left')  # ‡πÄ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡∏Ñ‡∏•‡∏¥‡∏õ‡∏¢‡πâ‡∏≠‡∏ô‡∏Å‡∏•‡∏±‡∏ö 5 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ\n",
    "                            last_move_time = current_time  # ‡∏£‡∏µ‡πÄ‡∏ã‡πá‡∏ï‡πÄ‡∏ß‡∏•‡∏≤‡∏Å‡∏≤‡∏£‡πÄ‡∏•‡∏∑‡πà‡∏≠‡∏ô\n",
    "\n",
    "                    # ‡πÑ‡∏õ‡∏Ñ‡∏•‡∏¥‡∏õ‡∏ñ‡∏±‡∏î‡πÑ‡∏õ\n",
    "                    elif fingers == [0, 1, 1, 1, 1]:  # ‡∏ä‡∏µ‡πâ 4 ‡∏ô‡∏¥‡πâ‡∏ß (‡∏ä‡∏µ‡πâ‡∏ô‡∏¥‡πâ‡∏ß, ‡∏ô‡∏¥‡πâ‡∏ß‡∏Å‡∏•‡∏≤‡∏á, ‡∏ô‡∏¥‡πâ‡∏ß‡∏ô‡∏≤‡∏á, ‡∏ô‡∏¥‡πâ‡∏ß‡∏Å‡πâ‡∏≠‡∏¢)\n",
    "                        if current_time - last_next_time > next_interval:  # 5 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ\n",
    "                            pyautogui.hotkey('shift', 'n')  # ‡πÉ‡∏ä‡πâ shift + n ‡πÑ‡∏õ‡∏Ñ‡∏•‡∏¥‡∏õ‡∏ñ‡∏±‡∏î‡πÑ‡∏õ\n",
    "                            last_next_time = current_time  # ‡∏£‡∏µ‡πÄ‡∏ã‡πá‡∏ï‡πÄ‡∏ß‡∏•‡∏≤‡∏Å‡∏≤‡∏£‡πÑ‡∏õ‡∏Ñ‡∏•‡∏¥‡∏õ‡∏ñ‡∏±‡∏î‡πÑ‡∏õ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a45076-07e7-4c8b-a87e-7c65461d225e",
   "metadata": {},
   "source": [
    "# 5. Evaluation\n",
    "Evaluation Criteria:\n",
    "- Assess volume adjustment accuracy by detecting whether hand gestures correctly control the volume.\n",
    "- Evaluate video playback control (skip, pause/play) to ensure expected functionality.\n",
    "\n",
    "Assessment Methods:\n",
    "- Verify that volume changes are neither too drastic nor insufficient.\n",
    "- Check the accuracy of simulated key presses for video control."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126ab50b-b4cc-4448-8b2b-4434a5c76257",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÅ‡∏õ‡∏•‡∏á‡∏£‡∏∞‡∏î‡∏±‡∏ö‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏ñ‡πâ‡∏≤‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÅ‡∏õ‡∏•‡∏á‡πÑ‡∏°‡πà‡∏°‡∏≤‡∏Å‡∏û‡∏≠\n",
    "if abs(volume.GetMasterVolumeLevelScalar() - last_volume) > 0.02:\n",
    "    volume.SetMasterVolumeLevelScalar(last_volume, None)\n",
    "\n",
    "# ‡∏Ñ‡∏ß‡∏ö‡∏Ñ‡∏∏‡∏°‡∏Å‡∏≤‡∏£‡πÄ‡∏•‡πà‡∏ô‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠ (‡πÄ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡∏Ñ‡∏•‡∏¥‡∏õ)\n",
    "if fingers == [0, 1, 0, 0, 0]:  # ‡πÄ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡∏Ñ‡∏•‡∏¥‡∏õ‡πÑ‡∏õ‡∏Ç‡πâ‡∏≤‡∏á‡∏´‡∏ô‡πâ‡∏≤\n",
    "    pyautogui.press('right')  # ‡∏Ñ‡∏ß‡∏ö‡∏Ñ‡∏∏‡∏°‡∏Å‡∏≤‡∏£‡πÄ‡∏•‡πà‡∏ô‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7839afe-17f9-4ac6-9ce1-53290a472232",
   "metadata": {},
   "source": [
    "# 6. Deployment\n",
    "Real-World Application:\n",
    "- The code can be implemented on computers with a compatible camera and software for controlling audio and video.\n",
    "- Users can conveniently control volume and video playback without using a mouse or keyboard.\n",
    "\n",
    "Installation:\n",
    "- Users need to install the required libraries, such as cv2, pycaw, pyautogui, and comtypes, before use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8cb573d-ec55-45dd-ae90-35b770179231",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á‡πÑ‡∏•‡∏ö‡∏£‡∏≤‡∏£‡∏µ‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô\n",
    "pip install opencv-python cvzone pycaw pyautogui comtypes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d3c539-510e-4ee5-a574-4e45b3d2292c",
   "metadata": {},
   "source": [
    "Maintenance:\n",
    "- Ensure proper lighting conditions to improve hand detection accuracy.\n",
    "- Enhance volume control for smoother adjustments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a810a09-392e-4699-94ab-956cd5814b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏ô‡∏∏‡πà‡∏°‡∏ô‡∏ß‡∏•\n",
    "smooth_factor = 0.2\n",
    "last_volume = (1 - smooth_factor) * last_volume + smooth_factor * volume_scalar  # ‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ô‡∏µ‡∏¢‡∏ô‡∏Ç‡∏∂‡πâ‡∏ô\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726697ef-5dcb-487a-8bb5-6bcf6d8bea65",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
